# -*- coding: utf-8 -*-
"""custom_model_loss.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aKWjLabOTkz137R9RU0BPlDMXLvA6u9H

tf2 keras 框架下实现  
参考  
  https://tensorflow.google.cn/guide/keras/train_and_evaluate#custom_metrics  
  https://tensorflow.google.cn/guide/keras/custom_callback  
  https://spaces.ac.cn/archives/4493  

两种loss实现的同时也对比了在keras自带Adam 和自定义AdaFactor 两种优化器下是否都可以执行
"""

! pip install git+https://www.github.com/bojone/bert4keras.git
import tensorflow as tf
from tensorflow.python.client import device_lib
print(tf.__version__)
tf.test.gpu_device_name()
device_lib.list_local_devices()
!nvidia-smi

"""## 标准输入loss_fun(y_true,y_pred)"""

from keras.layers import Input,Embedding,LSTM,Dense
from keras.models import Model
from keras import backend as K
from bert4keras.optimizers import *
import numpy as np

word_size = 128
nb_features = 10000
nb_classes = 10
encode_size = 64
# 构造模型
input = Input(shape=(None,))
embedded = Embedding(nb_features,word_size)(input)
encoder = LSTM(encode_size)(embedded)
predict = Dense(nb_classes, activation='softmax')(encoder)

def mycrossentropy(y_true, y_pred, e=0.1):
    loss1 = K.categorical_crossentropy(y_true, y_pred)
    loss2 = K.categorical_crossentropy(K.ones_like(y_pred)/nb_classes, y_pred)
    return (1-e)*loss1 + e*loss2

model = Model(inputs=input, outputs=predict)
model.compile(optimizer='adam', loss= mycrossentropy)

# 构造数据
data_size = 20
x_len = 10
x_array = np.random.randint(0,10,x_len*data_size).reshape((data_size,x_len))
#print(x_array)
y_len = nb_classes
y_array = [[0]*y_len for _ in list(range(data_size))]
y_ramdom = np.random.randint(0,y_len,data_size)
#print(y_ramdom)
for i,ind in enumerate(y_ramdom):
  y_array[i][ind]=1
y_array = np.array(y_array)
#print(y_array)
print(x_array.shape,y_array.shape)
# train
model.fit(x_array,y_array,epochs=1)

"""### 测试自定义Optimizer AdaFactor
说明此处自定义optimizer 采用bert4keras 作者封装的AdaFactor用于测试
后续会单独拆解如何自定义optimizer
"""

from bert4keras.optimizers import *
model2 = Model(inputs=input, outputs=predict)
model2.compile(optimizer=AdaFactor(), loss= mycrossentropy)
model2.fit(x_array,y_array,epochs=1)

"""## 自定义输入triplet loss"""

from keras.layers import Input,Embedding,LSTM,Dense,Lambda
from keras.layers.merge import dot
from keras.models import Model
from keras import backend as K

word_size = 128
nb_features = 10000
nb_classes = 10
encode_size = 64
margin = 0.1
# =============================================================================
## 模型构造
embedding = Embedding(nb_features,word_size)
lstm_encoder = LSTM(encode_size)

def encode(input):
    return lstm_encoder(embedding(input))

q_input = Input(shape=(None,))
a_right = Input(shape=(None,))
a_wrong = Input(shape=(None,))
q_encoded = encode(q_input)
a_right_encoded = encode(a_right)
a_wrong_encoded = encode(a_wrong)

q_encoded = Dense(encode_size)(q_encoded) #一般的做法是，直接讲问题和答案用同样的方法encode成向量后直接匹配，但我认为这是不合理的，我认为至少经过某个变换。

right_cos = dot([q_encoded,a_right_encoded], -1, normalize=True)
wrong_cos = dot([q_encoded,a_wrong_encoded], -1, normalize=True)

loss = Lambda(lambda x: K.relu(margin+x[0]-x[1]))([wrong_cos,right_cos])

model_train = Model(inputs=[q_input,a_right,a_wrong], outputs=loss)
model_q_encoder = Model(inputs=q_input, outputs=q_encoded)
model_a_encoder = Model(inputs=a_right, outputs=a_right_encoded)

model_train.compile(optimizer='adam', loss=lambda y_true,y_pred: y_pred)
model_q_encoder.compile(optimizer='adam', loss='mse')
model_a_encoder.compile(optimizer='adam', loss='mse')
# =============================================================================
## 数据构造
# q : id序列，a1 a2 与 q 一样尺寸的 0/1 位置标记
data_size = 20
x_len = 10
q = np.random.randint(0,10,x_len*data_size).reshape((data_size,x_len))
#print(q)

y_len = x_len
a1 = [[0]*y_len for _ in list(range(data_size))]
a2 = [[0]*y_len for _ in list(range(data_size))]
y_ramdom = np.random.randint(0,y_len,data_size)
y_ramdom = list(map(lambda x : x if x<9 else 0 ,y_ramdom))
y_wrong = [min(x+1,y_len-1) for x in y_ramdom]#负采样
#print(y_ramdom,y_wrong)

for i,ind in enumerate(y_ramdom):
  a1[i][ind]=1
for i,ind in enumerate(y_wrong):
  a2[i][ind]=1
a1 = np.array(a1)
a2 = np.array(a2)
#print(a1,a2)
print(q.shape,a1.shape)
y = np.random.randint(0,2,1*data_size).reshape((data_size,1))
#print(y,y.shape)
# =============================================================================
## train
model_train.fit([q,a1,a2], y, epochs=10)
#其中q,a1,a2分别是问题、正确答案、错误答案的batch，y是任意形状为(len(q),1)的矩阵

q_temp = np.random.randint(0,10,20).reshape((2,10))
print(model_q_encoder.predict(q_temp))
print(model_a_encoder.predict(q_temp))

"""### 测试自定义Optimizer AdaFactor"""

model_train2 = Model(inputs=[q_input,a_right,a_wrong], outputs=loss)
model_q_encoder2 = Model(inputs=q_input, outputs=q_encoded)
model_a_encoder2 = Model(inputs=a_right, outputs=a_right_encoded)

model_train2.compile(optimizer=AdaFactor(1e-3), loss=lambda y_true,y_pred: y_pred)
model_q_encoder2.compile(optimizer=AdaFactor(1e-3), loss='mse')
model_a_encoder2.compile(optimizer=AdaFactor(1e-3), loss='mse')

model_train2.fit([q,a1,a2], y, epochs=10)

q_temp = np.random.randint(0,10,20).reshape((2,10))
print(model_q_encoder.predict(q_temp))
print(model_a_encoder.predict(q_temp))