{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ir_v-IHGL5w6"
   },
   "source": [
    "测试 albert_small 情感分类  \n",
    "https://github.com/bojone/bert4keras/blob/master/examples/task_sentiment_albert.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kXahXQ-sMIDN"
   },
   "source": [
    "# part1:配置环境 + 加载文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "colab_type": "code",
    "id": "Pk5OZ22vM62G",
    "outputId": "c055323e-d712-4f99-b5f3-a6f9ca88d10e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://www.github.com/bojone/bert4keras.git\n",
      "  Cloning https://www.github.com/bojone/bert4keras.git to /tmp/pip-req-build-m9n9lr6n\n",
      "  Running command git clone -q https://www.github.com/bojone/bert4keras.git /tmp/pip-req-build-m9n9lr6n\n",
      "Requirement already satisfied (use --upgrade to upgrade): bert4keras==0.8.3 from git+https://www.github.com/bojone/bert4keras.git in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: keras<=2.3.1 in /usr/local/lib/python3.6/dist-packages (from bert4keras==0.8.3) (2.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (3.13)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (2.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (1.18.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (1.1.2)\n",
      "Building wheels for collected packages: bert4keras\n",
      "  Building wheel for bert4keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bert4keras: filename=bert4keras-0.8.3-cp36-none-any.whl size=41795 sha256=652c7ec7d8410062cb35deb6f6a3846f10759f74a443b444ba295e88add8391e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-t3l54x1y/wheels/12/58/83/8ff5c864b80c860e6d9e9e0d90c04fafca05d01d21f9f6fcba\n",
      "Successfully built bert4keras\n",
      "2.2.0\n",
      "Wed Jul 22 01:17:56 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   73C    P0    74W / 149W |    130MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#! pip install keras_bert\n",
    "! pip install git+https://www.github.com/bojone/bert4keras.git\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(tf.__version__)\n",
    "tf.test.gpu_device_name()\n",
    "device_lib.list_local_devices()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "OurdG48h8B0L",
    "outputId": "b1ad3220-1177-4f8a-e41f-4f9079ed76bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2duJDYznMyoM"
   },
   "source": [
    "### 加载数据文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "gdiF0jadMzvb",
    "outputId": "66934962-2184-44e5-9331-41007b2e11dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bert4keras'...\n",
      "remote: Enumerating objects: 5684, done.\u001b[K\n",
      "Receiving objects:   0% (1/5684)   \r",
      "Receiving objects:   1% (57/5684)   \r",
      "Receiving objects:   2% (114/5684)   \r",
      "Receiving objects:   3% (171/5684)   \r",
      "Receiving objects:   4% (228/5684)   \r",
      "Receiving objects:   5% (285/5684)   \r",
      "Receiving objects:   6% (342/5684)   \r",
      "Receiving objects:   7% (398/5684)   \r",
      "Receiving objects:   8% (455/5684)   \r",
      "Receiving objects:   9% (512/5684)   \r",
      "Receiving objects:  10% (569/5684)   \r",
      "Receiving objects:  11% (626/5684)   \r",
      "Receiving objects:  12% (683/5684)   \r",
      "Receiving objects:  13% (739/5684)   \r",
      "Receiving objects:  14% (796/5684)   \r",
      "Receiving objects:  15% (853/5684)   \r",
      "Receiving objects:  16% (910/5684)   \r",
      "Receiving objects:  17% (967/5684)   \r",
      "Receiving objects:  18% (1024/5684)   \r",
      "Receiving objects:  19% (1080/5684)   \r",
      "Receiving objects:  20% (1137/5684)   \r",
      "Receiving objects:  21% (1194/5684)   \r",
      "Receiving objects:  22% (1251/5684)   \r",
      "Receiving objects:  23% (1308/5684)   \r",
      "Receiving objects:  24% (1365/5684)   \r",
      "Receiving objects:  25% (1421/5684)   \r",
      "Receiving objects:  26% (1478/5684)   \r",
      "Receiving objects:  27% (1535/5684)   \r",
      "Receiving objects:  28% (1592/5684)   \r",
      "Receiving objects:  29% (1649/5684)   \r",
      "Receiving objects:  30% (1706/5684)   \r",
      "Receiving objects:  31% (1763/5684)   \r",
      "Receiving objects:  32% (1819/5684)   \r",
      "Receiving objects:  33% (1876/5684)   \r",
      "Receiving objects:  34% (1933/5684)   \r",
      "Receiving objects:  35% (1990/5684)   \r",
      "Receiving objects:  36% (2047/5684)   \r",
      "Receiving objects:  37% (2104/5684)   \r",
      "Receiving objects:  38% (2160/5684)   \r",
      "Receiving objects:  39% (2217/5684)   \r",
      "Receiving objects:  40% (2274/5684)   \r",
      "Receiving objects:  41% (2331/5684)   \r",
      "Receiving objects:  42% (2388/5684)   \r",
      "Receiving objects:  43% (2445/5684)   \r",
      "Receiving objects:  44% (2501/5684)   \r",
      "Receiving objects:  45% (2558/5684)   \r",
      "Receiving objects:  46% (2615/5684)   \r",
      "Receiving objects:  47% (2672/5684)   \r",
      "Receiving objects:  48% (2729/5684)   \r",
      "Receiving objects:  49% (2786/5684)   \r",
      "Receiving objects:  50% (2842/5684)   \r",
      "Receiving objects:  51% (2899/5684)   \r",
      "Receiving objects:  52% (2956/5684)   \r",
      "Receiving objects:  53% (3013/5684)   \r",
      "Receiving objects:  54% (3070/5684)   \r",
      "Receiving objects:  55% (3127/5684)   \r",
      "Receiving objects:  56% (3184/5684)   \r",
      "Receiving objects:  57% (3240/5684)   \r",
      "Receiving objects:  58% (3297/5684)   \r",
      "Receiving objects:  59% (3354/5684)   \r",
      "Receiving objects:  60% (3411/5684)   \r",
      "Receiving objects:  61% (3468/5684)   \r",
      "Receiving objects:  62% (3525/5684)   \r",
      "Receiving objects:  63% (3581/5684)   \r",
      "Receiving objects:  64% (3638/5684)   \r",
      "Receiving objects:  65% (3695/5684)   \r",
      "Receiving objects:  66% (3752/5684)   \r",
      "Receiving objects:  67% (3809/5684)   \r",
      "Receiving objects:  68% (3866/5684)   \r",
      "Receiving objects:  69% (3922/5684)   \r",
      "Receiving objects:  70% (3979/5684)   \r",
      "Receiving objects:  71% (4036/5684)   \r",
      "Receiving objects:  72% (4093/5684)   \r",
      "Receiving objects:  73% (4150/5684)   \r",
      "Receiving objects:  74% (4207/5684)   \r",
      "Receiving objects:  75% (4263/5684)   \r",
      "Receiving objects:  76% (4320/5684)   \r",
      "Receiving objects:  77% (4377/5684)   \r",
      "Receiving objects:  78% (4434/5684)   \r",
      "Receiving objects:  79% (4491/5684)   \r",
      "Receiving objects:  80% (4548/5684)   \r",
      "Receiving objects:  81% (4605/5684)   \r",
      "Receiving objects:  82% (4661/5684)   \r",
      "Receiving objects:  83% (4718/5684)   \r",
      "Receiving objects:  84% (4775/5684)   \r",
      "Receiving objects:  85% (4832/5684)   \r",
      "remote: Total 5684 (delta 0), reused 0 (delta 0), pack-reused 5684\u001b[K\n",
      "Receiving objects:  86% (4889/5684)   \r",
      "Receiving objects:  87% (4946/5684)   \r",
      "Receiving objects:  88% (5002/5684)   \r",
      "Receiving objects:  89% (5059/5684)   \r",
      "Receiving objects:  90% (5116/5684)   \r",
      "Receiving objects:  91% (5173/5684)   \r",
      "Receiving objects:  92% (5230/5684)   \r",
      "Receiving objects:  93% (5287/5684)   \r",
      "Receiving objects:  94% (5343/5684)   \r",
      "Receiving objects:  95% (5400/5684)   \r",
      "Receiving objects:  96% (5457/5684)   \r",
      "Receiving objects:  97% (5514/5684)   \r",
      "Receiving objects:  98% (5571/5684)   \r",
      "Receiving objects:  99% (5628/5684)   \r",
      "Receiving objects: 100% (5684/5684)   \r",
      "Receiving objects: 100% (5684/5684), 9.20 MiB | 23.38 MiB/s, done.\n",
      "Resolving deltas:   0% (0/3741)   \r",
      "Resolving deltas:   1% (52/3741)   \r",
      "Resolving deltas:   3% (144/3741)   \r",
      "Resolving deltas:   5% (197/3741)   \r",
      "Resolving deltas:   6% (241/3741)   \r",
      "Resolving deltas:   7% (265/3741)   \r",
      "Resolving deltas:   8% (324/3741)   \r",
      "Resolving deltas:   9% (339/3741)   \r",
      "Resolving deltas:  10% (379/3741)   \r",
      "Resolving deltas:  11% (435/3741)   \r",
      "Resolving deltas:  12% (462/3741)   \r",
      "Resolving deltas:  13% (523/3741)   \r",
      "Resolving deltas:  14% (526/3741)   \r",
      "Resolving deltas:  15% (597/3741)   \r",
      "Resolving deltas:  16% (601/3741)   \r",
      "Resolving deltas:  17% (638/3741)   \r",
      "Resolving deltas:  18% (709/3741)   \r",
      "Resolving deltas:  19% (711/3741)   \r",
      "Resolving deltas:  20% (773/3741)   \r",
      "Resolving deltas:  21% (789/3741)   \r",
      "Resolving deltas:  22% (830/3741)   \r",
      "Resolving deltas:  23% (894/3741)   \r",
      "Resolving deltas:  24% (900/3741)   \r",
      "Resolving deltas:  25% (947/3741)   \r",
      "Resolving deltas:  26% (974/3741)   \r",
      "Resolving deltas:  27% (1018/3741)   \r",
      "Resolving deltas:  28% (1049/3741)   \r",
      "Resolving deltas:  29% (1104/3741)   \r",
      "Resolving deltas:  30% (1149/3741)   \r",
      "Resolving deltas:  31% (1166/3741)   \r",
      "Resolving deltas:  32% (1212/3741)   \r",
      "Resolving deltas:  34% (1284/3741)   \r",
      "Resolving deltas:  35% (1331/3741)   \r",
      "Resolving deltas:  37% (1392/3741)   \r",
      "Resolving deltas:  38% (1447/3741)   \r",
      "Resolving deltas:  39% (1460/3741)   \r",
      "Resolving deltas:  40% (1518/3741)   \r",
      "Resolving deltas:  41% (1541/3741)   \r",
      "Resolving deltas:  42% (1589/3741)   \r",
      "Resolving deltas:  43% (1628/3741)   \r",
      "Resolving deltas:  44% (1656/3741)   \r",
      "Resolving deltas:  45% (1702/3741)   \r",
      "Resolving deltas:  46% (1751/3741)   \r",
      "Resolving deltas:  47% (1766/3741)   \r",
      "Resolving deltas:  49% (1838/3741)   \r",
      "Resolving deltas:  50% (1903/3741)   \r",
      "Resolving deltas:  51% (1912/3741)   \r",
      "Resolving deltas:  52% (1964/3741)   \r",
      "Resolving deltas:  55% (2068/3741)   \r",
      "Resolving deltas:  56% (2115/3741)   \r",
      "Resolving deltas:  58% (2193/3741)   \r",
      "Resolving deltas:  59% (2214/3741)   \r",
      "Resolving deltas:  60% (2247/3741)   \r",
      "Resolving deltas:  61% (2311/3741)   \r",
      "Resolving deltas:  62% (2327/3741)   \r",
      "Resolving deltas:  63% (2377/3741)   \r",
      "Resolving deltas:  64% (2398/3741)   \r",
      "Resolving deltas:  66% (2473/3741)   \r",
      "Resolving deltas:  67% (2515/3741)   \r",
      "Resolving deltas:  69% (2615/3741)   \r",
      "Resolving deltas:  70% (2620/3741)   \r",
      "Resolving deltas:  71% (2685/3741)   \r",
      "Resolving deltas:  72% (2708/3741)   \r",
      "Resolving deltas:  73% (2733/3741)   \r",
      "Resolving deltas:  74% (2791/3741)   \r",
      "Resolving deltas:  75% (2816/3741)   \r",
      "Resolving deltas:  76% (2874/3741)   \r",
      "Resolving deltas:  78% (2927/3741)   \r",
      "Resolving deltas:  79% (2959/3741)   \r",
      "Resolving deltas:  80% (3026/3741)   \r",
      "Resolving deltas:  81% (3059/3741)   \r",
      "Resolving deltas:  82% (3081/3741)   \r",
      "Resolving deltas:  83% (3109/3741)   \r",
      "Resolving deltas:  84% (3161/3741)   \r",
      "Resolving deltas:  85% (3186/3741)   \r",
      "Resolving deltas:  86% (3236/3741)   \r",
      "Resolving deltas:  87% (3258/3741)   \r",
      "Resolving deltas:  88% (3307/3741)   \r",
      "Resolving deltas:  89% (3336/3741)   \r",
      "Resolving deltas:  90% (3379/3741)   \r",
      "Resolving deltas:  91% (3409/3741)   \r",
      "Resolving deltas:  92% (3449/3741)   \r",
      "Resolving deltas:  93% (3484/3741)   \r",
      "Resolving deltas:  94% (3526/3741)   \r",
      "Resolving deltas:  95% (3557/3741)   \r",
      "Resolving deltas:  96% (3593/3741)   \r",
      "Resolving deltas:  97% (3635/3741)   \r",
      "Resolving deltas:  98% (3667/3741)   \r",
      "Resolving deltas:  99% (3709/3741)   \r",
      "Resolving deltas: 100% (3741/3741)   \r",
      "Resolving deltas: 100% (3741/3741), done.\n",
      "Archive:  /content/bert4keras/examples/datasets/sentiment.zip\n",
      "   creating: /content/sample_data/sentiment/\n",
      "  inflating: /content/sample_data/sentiment/sentiment.test.data  \n",
      "  inflating: /content/sample_data/sentiment/sentiment.train.data  \n",
      "  inflating: /content/sample_data/sentiment/sentiment.valid.data  \n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/bojone/bert4keras.git\n",
    "! unzip -d '/content/sample_data' \"/content/bert4keras/examples/datasets/sentiment.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSoMYIdgMGWi"
   },
   "source": [
    "#### 1.1 加载ALbert_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "a-d9Mvx4q40u",
    "outputId": "e0bb6ea0-f2f6-4282-b4fa-f922a05ade65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-22 01:52:33--  https://storage.googleapis.com/albert_zh/albert_small_zh_google.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.124.128, 172.217.212.128, 172.217.214.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.124.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 53458815 (51M) [application/zip]\n",
      "Saving to: ‘albert_small_zh_google.zip’\n",
      "\n",
      "albert_small_zh_goo 100%[===================>]  50.98M   103MB/s    in 0.5s    \n",
      "\n",
      "2020-07-22 01:52:34 (103 MB/s) - ‘albert_small_zh_google.zip’ saved [53458815/53458815]\n",
      "\n",
      "Archive:  /content/albert_small_zh_google.zip\n",
      "  inflating: /content/albert_small_zh_google/albert_config_small_google.json  \n",
      "  inflating: /content/albert_small_zh_google/albert_model.ckpt.data-00000-of-00001  \n",
      "  inflating: /content/albert_small_zh_google/albert_model.ckpt.index  \n",
      "  inflating: /content/albert_small_zh_google/albert_model.ckpt.meta  \n",
      "  inflating: /content/albert_small_zh_google/checkpoint  \n",
      "  inflating: /content/albert_small_zh_google/vocab.txt  \n"
     ]
    }
   ],
   "source": [
    "! wget https://storage.googleapis.com/albert_zh/albert_small_zh_google.zip\n",
    "! unzip -o \"/content/albert_small_zh_google.zip\" -d '/content/albert_small_zh_google'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RD5YgLEwMbAz"
   },
   "source": [
    "#### 1.2 Albert_large_zh\n",
    "\n",
    "该版本不能被直接使用需要转换  \n",
    "https://github.com/bojone/albert_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "P8cQdyIxMF-S",
    "outputId": "595cc20b-f323-44a2-9a06-1115391d2174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/My Drive/local_copy/albert_large_google_zh.zip\n",
      "   creating: /content/albert_large_google_zh/albert_large_google_zh/\n",
      "  inflating: /content/albert_large_google_zh/albert_large_google_zh/albert_model.ckpt.data-00000-of-00001  \n",
      "  inflating: /content/albert_large_google_zh/albert_large_google_zh/albert_model.ckpt.index  \n",
      "  inflating: /content/albert_large_google_zh/albert_large_google_zh/checkpoint  \n",
      "  inflating: /content/albert_large_google_zh/albert_large_google_zh/vocab.txt  \n",
      "  inflating: /content/albert_large_google_zh/albert_large_google_zh/albert_config.json  \n"
     ]
    }
   ],
   "source": [
    "## 百度下载的 albert_large\n",
    "! unzip -o \"/content/drive/My Drive/local_copy/albert_large_google_zh.zip\" -d '/content/albert_large_google_zh'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DRy5MUYMMkfA"
   },
   "source": [
    "#### 1.3 Chinese-BERT-wwm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "3u7jIOpcLgw-",
    "outputId": "ec46e19a-1a6b-43a9-cf8a-d6e9fe42ccc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/My Drive/Colab Notebooks/chinese_wwm_L-12_H-768_A-12.zip\n",
      "   creating: publish/\n",
      "  inflating: publish/vocab.txt       \n",
      "  inflating: publish/bert_model.ckpt.index  \n",
      "  inflating: publish/bert_model.ckpt.data-00000-of-00001  \n",
      "  inflating: publish/bert_config.json  \n",
      "  inflating: publish/bert_model.ckpt.meta  \n"
     ]
    }
   ],
   "source": [
    "# 加载drive中的bert checkpoint\n",
    "#! wget https://github.com/ymcui/Chinese-BERT-wwm\n",
    "! unzip \"/content/drive/My Drive/Colab Notebooks/chinese_wwm_L-12_H-768_A-12.zip\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-xj6GImvNAL4"
   },
   "source": [
    "# part2 配置全局参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OX4N6WqVNVv1",
    "outputId": "887209b8-1265-457b-aa7f-da4d7f083500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import codecs\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from bert4keras.backend import keras, set_gelu\n",
    "from bert4keras.tokenizers import Tokenizer\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.optimizers import Adam, extend_with_piecewise_linear_lr\n",
    "from bert4keras.snippets import sequence_padding, DataGenerator\n",
    "from bert4keras.snippets import open\n",
    "from keras.layers import Lambda, Dense\n",
    "from bert4keras.optimizers import *\n",
    "\n",
    "set_gelu('tanh')  # 切换gelu版本\n",
    "\n",
    "num_classes = 2\n",
    "maxlen = 128\n",
    "batch_size = 64\n",
    "# 1 训练数据文件路径\n",
    "data_dir = \"/content/sample_data/sentiment\"\n",
    "train_data_dir = data_dir + \"/sentiment.train.data\"\n",
    "valid_data_dir = data_dir + \"/sentiment.valid.data\"\n",
    "test_data_dir = data_dir + \"/sentiment.test.data\"\n",
    "\n",
    "print(os.path.exists(train_data_dir))\n",
    "\n",
    "# 3 训练模型文件路径\n",
    "checkpoint_dir = 'checkpoint/subject_extract2'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "# 4 结果输出路径    \n",
    "outputdir = '/content/drive/My Drive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P6i5jLTAQTIy"
   },
   "source": [
    "### 2.1 albert_small_google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQyaffczQTvd"
   },
   "outputs": [],
   "source": [
    "\n",
    "config_path = '/content/albert_small_zh_google/albert_config_small_google.json'\n",
    "checkpoint_path = '/content/albert_small_zh_google/albert_model.ckpt'\n",
    "dict_path = '/content/albert_small_zh_google/vocab.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UUeM6Rb7Qfb4"
   },
   "source": [
    "### 2.2 albert_large_google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k78JTxt0Qd71"
   },
   "outputs": [],
   "source": [
    "model_dir = \"/content/albert_large_google_zh/albert_large_google_zh\"\n",
    "config_path = model_dir + '/albert_config.json'\n",
    "checkpoint_path = model_dir + '/albert_model.ckpt'\n",
    "dict_path = model_dir + '/vocab.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MoPb3RlRQjmH"
   },
   "source": [
    "### 2.3 bert_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VgLTSoPvQ1wL",
    "outputId": "3456fa9c-4c2d-4c1f-b84c-2ebabbb615b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint path :  True\n"
     ]
    }
   ],
   "source": [
    "config_path = './publish/bert_config.json'\n",
    "checkpoint_path = './publish/bert_model.ckpt'\n",
    "dict_path = './publish/vocab.txt'\n",
    " \n",
    "print('load checkpoint path : ',os.path.exists(config_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vGC-5O-pN3Ll"
   },
   "source": [
    "# part 3 模型部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ij8GK-g6NYZj"
   },
   "source": [
    "## 数据构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2rBLHaIDNZLX"
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_data(filename):\n",
    "    D = []\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        for l in f:\n",
    "            text, label = l.strip().split('\\t')\n",
    "            D.append((text, int(label)))\n",
    "    return D\n",
    "\n",
    "\n",
    "# 加载数据集\n",
    "train_data = load_data(train_data_dir)\n",
    "valid_data = load_data(valid_data_dir)\n",
    "test_data = load_data(test_data_dir)\n",
    "\n",
    "# 建立分词器\n",
    "tokenizer = Tokenizer(dict_path, do_lower_case=True)\n",
    "\n",
    "class data_generator(DataGenerator):\n",
    "    \"\"\"数据生成器\n",
    "    \"\"\"\n",
    "    def __iter__(self, random=False):\n",
    "        batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n",
    "        for is_end, (text, label) in self.sample(random):\n",
    "            token_ids, segment_ids = tokenizer.encode(text, maxlen=maxlen)\n",
    "            batch_token_ids.append(token_ids)\n",
    "            batch_segment_ids.append(segment_ids)\n",
    "            batch_labels.append([label])\n",
    "            if len(batch_token_ids) == self.batch_size or is_end:\n",
    "                batch_token_ids = sequence_padding(batch_token_ids)\n",
    "                batch_segment_ids = sequence_padding(batch_segment_ids)\n",
    "                batch_labels = sequence_padding(batch_labels)\n",
    "                yield [batch_token_ids, batch_segment_ids], batch_labels\n",
    "                batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n",
    "\n",
    "# 转换数据集\n",
    "train_generator = data_generator(train_data, batch_size)\n",
    "valid_generator = data_generator(valid_data, batch_size)\n",
    "test_generator = data_generator(test_data, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "id": "FBHfC8x_RtCK",
    "outputId": "405c2fb4-5f12-4021-8640-c0a8f73bd5a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids : [ 101 3238 8024 5632 2346 1405 5632 2346  749 8024 1157 1157 3018 3209\n",
      " 4635 8024 6821 1372 3322 2094 3064 8388 3198 7509 7030  679 5543 4500\n",
      " 5011 6444 4638 8024 6206 4500 2797 3322 2340  904 4638  677  678 7241\n",
      " 6444 5688  511 2597  679 2533 2769 4500 5011 4157  749 3187 3144 3613\n",
      " 3064 3123 1690 3297 1400 7481 3300  702 1898 7509 1920 2207 1377 6444\n",
      " 5688 3403 2562 6963 3766 1353 2418 8024  809  711 8388 1776 2957  749\n",
      " 8013 1963 3362  679 5543 4500  117  711  784  720 6820 6206 6821 3416\n",
      " 2094  976 4518 7481  117 4696 3221 4638  106 5314 3322 1351  812 2990\n",
      "  702 7008 8024 1920 2157 3800 2692  671  678 1416  102    0    0    0\n",
      "    0    0] \n",
      "text:晕，自己吓自己了，刚刚搞明白，这只机子播mp3时音量不能用笔调的，要用手机左侧的上下键调节。怪不得我用笔点了无数次播放器最后面有个声音大小可调节标志都没反应，以为mp3坏掉了！如果不能用, 为什么还要这样子做界面, 真是的! 给机友们提个醒，大家注意一下吧\n",
      "label:[0]\n"
     ]
    }
   ],
   "source": [
    "# 查看数据\n",
    "tag = 0\n",
    "for i in train_generator.forfit():\n",
    "  tag +=1\n",
    "  if tag>1:\n",
    "    break\n",
    "  #print(i,len(i))\n",
    "  #print(i[0],'\\n',i[1])\n",
    "  #print(i[0][0],'\\n',i[0][0].shape)\n",
    "  #print(i[0][1],'\\n',i[0][1].shape)\n",
    "  #print(i[1],'\\n',i[1].shape)\n",
    "  print('ids : {} \\ntext:{}\\nlabel:{}'.format(i[0][0][0],tokenizer.decode(i[0][0][0]),i[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DB0scGYCNteG"
   },
   "source": [
    "##  模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxuxf4tZSqOS"
   },
   "source": [
    "### ALBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZ5Ep4cRPVg3"
   },
   "source": [
    "#### 不训练层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MfxH2ic9Nm9E"
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "# 加载预训练模型\n",
    "## return_keras_model=False 不训练层\n",
    "bert = build_transformer_model(\n",
    "    config_path=config_path,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    model='albert',\n",
    "    return_keras_model=False,\n",
    ")\n",
    "\n",
    "output = Lambda(lambda x: x[:, 0], name='CLS-token')(bert.model.output)#只取cls值\n",
    "output = Dense(\n",
    "    units=num_classes,\n",
    "    activation='softmax',\n",
    "    kernel_initializer=bert.initializer\n",
    ")(output)\n",
    "\n",
    "model = keras.models.Model(bert.model.input, output)\n",
    "model.summary()\n",
    "\n",
    "# 派生为带分段线性学习率的优化器。\n",
    "# 其中name参数可选，但最好填入，以区分不同的派生优化器。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hwsoYfWKPdRO"
   },
   "source": [
    "#### 训练层--代码没改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S0o51F6IPbGI"
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "# 加载预训练模型\n",
    "## return_keras_model=False 不训练层\n",
    "bert = build_transformer_model(\n",
    "    config_path=config_path,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    model='albert',\n",
    "    return_keras_model=False,\n",
    ")\n",
    "\n",
    "output = Lambda(lambda x: x[:, 0], name='CLS-token')(bert.model.output)#只取cls值\n",
    "output = Dense(\n",
    "    units=num_classes,\n",
    "    activation='softmax',\n",
    "    kernel_initializer=bert.initializer\n",
    ")(output)\n",
    "\n",
    "model = keras.models.Model(bert.model.input, output)\n",
    "model.summary()\n",
    "\n",
    "# 派生为带分段线性学习率的优化器。\n",
    "# 其中name参数可选，但最好填入，以区分不同的派生优化器。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PuqSRqxvSvuy"
   },
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ih5LU777S6Xk"
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "bert = build_transformer_model(\n",
    "    config_path=config_path,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    return_keras_model=True,\n",
    ")\n",
    "layer_name = 'Transformer-3-FeedForward-Norm'                                    \n",
    "\n",
    "\n",
    "output = Lambda(lambda x: x[:, 0], name='CLS-token')(bert.get_layer(layer_name).output)#只取cls值\n",
    "output = Dense(\n",
    "    units=num_classes,\n",
    "    activation='softmax',\n",
    "    kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.02)\n",
    ")(output)\n",
    "\n",
    "model = keras.models.Model(bert.input, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1W14hKLNOBsR"
   },
   "source": [
    "### callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0yr4SHR4OFYG"
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(data):\n",
    "    total, right = 0., 0.\n",
    "    for x_true, y_true in data:\n",
    "        y_pred = model.predict(x_true).argmax(axis=1)\n",
    "        y_true = y_true[:, 0]\n",
    "        total += len(y_true)\n",
    "        right += (y_true == y_pred).sum()\n",
    "    return right / total\n",
    "\n",
    "\n",
    "class Evaluator(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.best_val_acc = 0.\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_acc = evaluate(valid_generator)\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            model.save_weights('best_model.weights')\n",
    "        test_acc = evaluate(test_generator)\n",
    "        print(\n",
    "            u'val_acc: %.5f, best_val_acc: %.5f, test_acc: %.5f\\n' %\n",
    "            (val_acc, self.best_val_acc, test_acc)\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZpGsJOzeRbFb"
   },
   "source": [
    "### Optimizer  \n",
    "    Adam AdaFactor AdaX   \n",
    "\n",
    "优秀的老手用SGD精调"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-q0bzcFq9uuI"
   },
   "source": [
    "### 优化器策略  \n",
    "#### 1 权重衰减\n",
    "    extend_with_weight_decay  \n",
    "\n",
    "#### 2 层自适应学习率\n",
    "    extend_with_layer_adaptation\n",
    "\n",
    "#### 3 分段线性学习率\n",
    "    extend_with_piecewise_linear_lr  \n",
    "\n",
    "#### 4 梯度累积\n",
    "    extend_with_gradient_accumulation  \n",
    "\n",
    "#### 5 带有look ahead的优化器   \n",
    "    extend_with_lookahead  \n",
    "https://arxiv.org/abs/1907.08610\n",
    "steps_per_slow_update: 即论文中的k；\n",
    "slow_step_size: 即论文中的alpha。\n",
    "\n",
    "#### 6 懒惰更新 \n",
    "    extend_with_lazy_optimization   \n",
    "使得部分权重（尤其是embedding）只有在梯度不等于0时\n",
    "        才发生更新。  \n",
    "\n",
    "#### 7 EMA（权重滑动平均）\n",
    "    extend_with_exponential_moving_average  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B5uN4c9EOx1E"
   },
   "source": [
    "#### 3.1 Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "colab_type": "code",
    "id": "uVSKVOFFPWlR",
    "outputId": "4dd9dbdb-3cc7-4d77-f911-4e768b47b269"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "264/264 [==============================] - 151s 572ms/step - loss: 0.3020 - accuracy: 0.8769\n",
      "val_acc: 0.91994, best_val_acc: 0.91994, test_acc: 0.91852\n",
      "\n",
      "Epoch 2/10\n",
      "264/264 [==============================] - 147s 556ms/step - loss: 0.1612 - accuracy: 0.9421\n",
      "val_acc: 0.93984, best_val_acc: 0.93984, test_acc: 0.93321\n",
      "\n",
      "Epoch 3/10\n",
      "264/264 [==============================] - 147s 556ms/step - loss: 0.0949 - accuracy: 0.9681\n",
      "val_acc: 0.93226, best_val_acc: 0.93984, test_acc: 0.93415\n",
      "\n",
      "Epoch 4/10\n",
      "264/264 [==============================] - 147s 555ms/step - loss: 0.0594 - accuracy: 0.9818\n",
      "val_acc: 0.92184, best_val_acc: 0.93984, test_acc: 0.92942\n",
      "\n",
      "Epoch 5/10\n",
      "264/264 [==============================] - 147s 556ms/step - loss: 0.0459 - accuracy: 0.9849\n",
      "val_acc: 0.93652, best_val_acc: 0.93984, test_acc: 0.94173\n",
      "\n",
      "Epoch 6/10\n",
      "264/264 [==============================] - 147s 556ms/step - loss: 0.0389 - accuracy: 0.9861\n",
      "val_acc: 0.94079, best_val_acc: 0.94079, test_acc: 0.94315\n",
      "\n",
      "Epoch 7/10\n",
      "264/264 [==============================] - 147s 555ms/step - loss: 0.0305 - accuracy: 0.9902\n",
      "val_acc: 0.93605, best_val_acc: 0.94079, test_acc: 0.93415\n",
      "\n",
      "Epoch 8/10\n",
      "264/264 [==============================] - 147s 555ms/step - loss: 0.0299 - accuracy: 0.9897\n",
      "val_acc: 0.93131, best_val_acc: 0.94079, test_acc: 0.93984\n",
      "\n",
      "Epoch 9/10\n",
      "264/264 [==============================] - 146s 554ms/step - loss: 0.0184 - accuracy: 0.9931\n",
      "val_acc: 0.92989, best_val_acc: 0.94079, test_acc: 0.93937\n",
      "\n",
      "Epoch 10/10\n",
      "264/264 [==============================] - 147s 556ms/step - loss: 0.0197 - accuracy: 0.9928\n",
      "val_acc: 0.93842, best_val_acc: 0.94079, test_acc: 0.93510\n",
      "\n",
      "final test acc: 0.943155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "evaluator = Evaluator()\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QerDtEgUPO17"
   },
   "source": [
    "##### 3.1.1 线性AdamLR\n",
    "可以分段调控 ，线性变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "4GCb0DBakeg8",
    "outputId": "e4ff209b-cfb2-494f-8feb-b09caf8d2722"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "264/264 [==============================] - 80s 302ms/step - loss: 0.4689 - accuracy: 0.7638\n",
      "val_acc: 0.88726, best_val_acc: 0.88726, test_acc: 0.88205\n",
      "\n",
      "Epoch 2/5\n",
      "264/264 [==============================] - 80s 304ms/step - loss: 0.2379 - accuracy: 0.9106\n",
      "val_acc: 0.92468, best_val_acc: 0.92468, test_acc: 0.91757\n",
      "\n",
      "Epoch 3/5\n",
      "264/264 [==============================] - 81s 306ms/step - loss: 0.1656 - accuracy: 0.9418\n",
      "val_acc: 0.93368, best_val_acc: 0.93368, test_acc: 0.92752\n",
      "\n",
      "Epoch 4/5\n",
      "264/264 [==============================] - 81s 306ms/step - loss: 0.1188 - accuracy: 0.9582\n",
      "val_acc: 0.93321, best_val_acc: 0.93368, test_acc: 0.92942\n",
      "\n",
      "Epoch 5/5\n",
      "264/264 [==============================] - 81s 307ms/step - loss: 0.0707 - accuracy: 0.9765\n",
      "val_acc: 0.94173, best_val_acc: 0.94173, test_acc: 0.93321\n",
      "\n",
      "final test acc: 0.933207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AdamLR = extend_with_piecewise_linear_lr(Adam, name='AdamLR')\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    optimizer=AdamLR(learning_rate=1e-4, lr_schedule={\n",
    "        1000: 1,\n",
    "        2000: 0.1\n",
    "    }),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "czTbnOCKEJjQ"
   },
   "source": [
    "##### 3.1.2 EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2Z8-iuzD54b"
   },
   "outputs": [],
   "source": [
    "\n",
    "AdamEMA = extend_with_exponential_moving_average(Adam, name='AdamEMA')\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    optimizer=AdamEMA(learning_rate=1e-4),\n",
    "    metrics=['accuracy'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "z1QBNGnSE9Hj",
    "outputId": "c21c2408-bda9-4f6d-c8f3-2af98c8b49ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "264/264 [==============================] - 31s 116ms/step - loss: 0.7227 - accuracy: 0.5087\n",
      "val_acc: 0.49124, best_val_acc: 0.49124, test_acc: 0.49834\n",
      "\n",
      "Epoch 2/5\n",
      "264/264 [==============================] - 28s 108ms/step - loss: 0.7231 - accuracy: 0.5087\n",
      "val_acc: 0.49124, best_val_acc: 0.49124, test_acc: 0.49834\n",
      "\n",
      "Epoch 3/5\n",
      "264/264 [==============================] - 28s 107ms/step - loss: 0.7228 - accuracy: 0.5087\n",
      "val_acc: 0.49124, best_val_acc: 0.49124, test_acc: 0.49834\n",
      "\n",
      "Epoch 4/5\n",
      "264/264 [==============================] - 28s 108ms/step - loss: 0.7230 - accuracy: 0.5087\n",
      "val_acc: 0.49124, best_val_acc: 0.49124, test_acc: 0.49834\n",
      "\n",
      "Epoch 5/5\n",
      "264/264 [==============================] - 28s 108ms/step - loss: 0.7231 - accuracy: 0.5087\n",
      "val_acc: 0.49124, best_val_acc: 0.49124, test_acc: 0.49834\n",
      "\n",
      "final test acc: 0.498342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eK4Q2wrQEPM9"
   },
   "source": [
    "#####3.1.3 梯度累计 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42FNu4S3FnQT"
   },
   "outputs": [],
   "source": [
    "\n",
    "AdamGACC = extend_with_gradient_accumulation(Adam, name='AdamGACC')\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    optimizer=AdamGACC(learning_rate=1e-4),\n",
    "    metrics=['accuracy'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "VylZvHjyEAhn",
    "outputId": "7ed45b6f-87f9-42fa-aaee-089d4f6dd838"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "264/264 [==============================] - 89s 337ms/step - loss: 0.4022 - accuracy: 0.8081\n",
      "val_acc: 0.90242, best_val_acc: 0.90242, test_acc: 0.90289\n",
      "\n",
      "Epoch 2/5\n",
      "264/264 [==============================] - 85s 323ms/step - loss: 0.1898 - accuracy: 0.9279\n",
      "val_acc: 0.92942, best_val_acc: 0.92942, test_acc: 0.92184\n",
      "\n",
      "Epoch 3/5\n",
      "264/264 [==============================] - 85s 323ms/step - loss: 0.0912 - accuracy: 0.9666\n",
      "val_acc: 0.92326, best_val_acc: 0.92942, test_acc: 0.92468\n",
      "\n",
      "Epoch 4/5\n",
      "264/264 [==============================] - 85s 323ms/step - loss: 0.0388 - accuracy: 0.9867\n",
      "val_acc: 0.94458, best_val_acc: 0.94458, test_acc: 0.93273\n",
      "\n",
      "Epoch 5/5\n",
      "264/264 [==============================] - 85s 322ms/step - loss: 0.0263 - accuracy: 0.9910\n",
      "val_acc: 0.93084, best_val_acc: 0.94458, test_acc: 0.92136\n",
      "\n",
      "final test acc: 0.921364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator()\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "\n",
    "#model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZwaLqP2IQPH"
   },
   "source": [
    "##### 3.3.4 层自适应\n",
    "extend_with_layer_adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "BSv7RJ9HIU9-",
    "outputId": "b389df14-f2ff-4ea3-e66a-6578282c1744"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "264/264 [==============================] - 89s 338ms/step - loss: 0.3888 - accuracy: 0.8168\n",
      "val_acc: 0.91805, best_val_acc: 0.91805, test_acc: 0.91047\n",
      "\n",
      "Epoch 2/5\n",
      "264/264 [==============================] - 86s 325ms/step - loss: 0.1841 - accuracy: 0.9318\n",
      "val_acc: 0.93605, best_val_acc: 0.93605, test_acc: 0.93368\n",
      "\n",
      "Epoch 3/5\n",
      "264/264 [==============================] - 86s 325ms/step - loss: 0.1074 - accuracy: 0.9622\n",
      "val_acc: 0.94458, best_val_acc: 0.94458, test_acc: 0.93463\n",
      "\n",
      "Epoch 4/5\n",
      "264/264 [==============================] - 86s 325ms/step - loss: 0.0598 - accuracy: 0.9808\n",
      "val_acc: 0.94126, best_val_acc: 0.94458, test_acc: 0.93510\n",
      "\n",
      "Epoch 5/5\n",
      "264/264 [==============================] - 86s 324ms/step - loss: 0.0335 - accuracy: 0.9892\n",
      "val_acc: 0.93794, best_val_acc: 0.94458, test_acc: 0.93652\n",
      "\n",
      "final test acc: 0.934628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AdamLA = extend_with_layer_adaptation(Adam, name='AdamLA')\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    optimizer=AdamLA(learning_rate=1e-4),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "evaluator = Evaluator()\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qLSjX8lRH9UP"
   },
   "source": [
    "##### 3.3.5 权重衰减  \n",
    "extend_with_weight_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "Lh6KYOrFIA64",
    "outputId": "a4d5c192-1a9c-4732-c3fd-bee73980a008"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "264/264 [==============================] - 86s 326ms/step - loss: 0.1451 - accuracy: 0.9462\n",
      "val_acc: 0.94315, best_val_acc: 0.94315, test_acc: 0.93558\n",
      "\n",
      "Epoch 2/5\n",
      "264/264 [==============================] - 83s 315ms/step - loss: 0.0742 - accuracy: 0.9739\n",
      "val_acc: 0.93842, best_val_acc: 0.94315, test_acc: 0.93321\n",
      "\n",
      "Epoch 3/5\n",
      "264/264 [==============================] - 83s 316ms/step - loss: 0.0477 - accuracy: 0.9834\n",
      "val_acc: 0.93368, best_val_acc: 0.94315, test_acc: 0.94031\n",
      "\n",
      "Epoch 4/5\n",
      "264/264 [==============================] - 83s 316ms/step - loss: 0.0336 - accuracy: 0.9884\n",
      "val_acc: 0.94268, best_val_acc: 0.94315, test_acc: 0.93937\n",
      "\n",
      "Epoch 5/5\n",
      "264/264 [==============================] - 83s 315ms/step - loss: 0.0265 - accuracy: 0.9898\n",
      "val_acc: 0.93605, best_val_acc: 0.94315, test_acc: 0.93842\n",
      "\n",
      "final test acc: 0.935576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AdamWdecay = extend_with_weight_decay(Adam, name='AdamWdecay')\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    optimizer=AdamWdecay(learning_rate=1e-4, ),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "evaluator = Evaluator()\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ANIfW1pKM15s"
   },
   "source": [
    "#### 3.2 SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QEvowhtxW_yz"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "sUGaUA6PW65B",
    "outputId": "c3ec68c9-d843-49fb-e53b-a85fe9e872d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "264/264 [==============================] - 148s 560ms/step - loss: 0.0135 - accuracy: 0.9955\n",
      "val_acc: 0.93700, best_val_acc: 0.93700, test_acc: 0.94505\n",
      "\n",
      "Epoch 2/5\n",
      "264/264 [==============================] - 146s 552ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "val_acc: 0.94268, best_val_acc: 0.94268, test_acc: 0.94268\n",
      "\n",
      "Epoch 3/5\n",
      "264/264 [==============================] - 146s 552ms/step - loss: 0.0021 - accuracy: 0.9992\n",
      "val_acc: 0.94363, best_val_acc: 0.94363, test_acc: 0.94410\n",
      "\n",
      "Epoch 4/5\n",
      "264/264 [==============================] - 145s 551ms/step - loss: 0.0016 - accuracy: 0.9991\n",
      "val_acc: 0.94315, best_val_acc: 0.94363, test_acc: 0.94505\n",
      "\n",
      "Epoch 5/5\n",
      "264/264 [==============================] - 145s 551ms/step - loss: 0.0014 - accuracy: 0.9992\n",
      "val_acc: 0.94315, best_val_acc: 0.94363, test_acc: 0.94458\n",
      "\n",
      "final test acc: 0.944102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=SGD(learning_rate=1e-3, decay=1e-6, momentum=0.9),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "evaluator = Evaluator()\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VP9CxdoCIGTW"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "SGDLhead = extend_with_weight_decay(SGD, name='SGDLhead')\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    optimizer=SGDLhead(learning_rate=1e-3, decay=1e-6, momentum=0.9),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "evaluator = Evaluator()\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3IMMmTWiO9Ld"
   },
   "source": [
    "#### 3.3 AdaFactor\n",
    "这个优化器lr batch_size 需要大一点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "iAMzvvclZIHj",
    "outputId": "c37802e0-a47e-400f-8fc4-bb30c8f43973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'adafactor'...\n",
      "remote: Enumerating objects: 18, done.\u001b[K\n",
      "remote: Counting objects:   5% (1/18)\u001b[K\r",
      "remote: Counting objects:  11% (2/18)\u001b[K\r",
      "remote: Counting objects:  16% (3/18)\u001b[K\r",
      "remote: Counting objects:  22% (4/18)\u001b[K\r",
      "remote: Counting objects:  27% (5/18)\u001b[K\r",
      "remote: Counting objects:  33% (6/18)\u001b[K\r",
      "remote: Counting objects:  38% (7/18)\u001b[K\r",
      "remote: Counting objects:  44% (8/18)\u001b[K\r",
      "remote: Counting objects:  50% (9/18)\u001b[K\r",
      "remote: Counting objects:  55% (10/18)\u001b[K\r",
      "remote: Counting objects:  61% (11/18)\u001b[K\r",
      "remote: Counting objects:  66% (12/18)\u001b[K\r",
      "remote: Counting objects:  72% (13/18)\u001b[K\r",
      "remote: Counting objects:  77% (14/18)\u001b[K\r",
      "remote: Counting objects:  83% (15/18)\u001b[K\r",
      "remote: Counting objects:  88% (16/18)\u001b[K\r",
      "remote: Counting objects:  94% (17/18)\u001b[K\r",
      "remote: Counting objects: 100% (18/18)\u001b[K\r",
      "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
      "remote: Compressing objects:   6% (1/15)\u001b[K\r",
      "remote: Compressing objects:  13% (2/15)\u001b[K\r",
      "remote: Compressing objects:  20% (3/15)\u001b[K\r",
      "remote: Compressing objects:  26% (4/15)\u001b[K\r",
      "remote: Compressing objects:  33% (5/15)\u001b[K\r",
      "remote: Compressing objects:  40% (6/15)\u001b[K\r",
      "remote: Compressing objects:  46% (7/15)\u001b[K\r",
      "remote: Compressing objects:  53% (8/15)\u001b[K\r",
      "remote: Compressing objects:  60% (9/15)\u001b[K\r",
      "remote: Compressing objects:  66% (10/15)\u001b[K\r",
      "remote: Compressing objects:  73% (11/15)\u001b[K\r",
      "remote: Compressing objects:  80% (12/15)\u001b[K\r",
      "remote: Compressing objects:  86% (13/15)\u001b[K\r",
      "remote: Compressing objects:  93% (14/15)\u001b[K\r",
      "remote: Compressing objects: 100% (15/15)\u001b[K\r",
      "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
      "remote: Total 18 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects:   5% (1/18)   \r",
      "Unpacking objects:  11% (2/18)   \r",
      "Unpacking objects:  16% (3/18)   \r",
      "Unpacking objects:  22% (4/18)   \r",
      "Unpacking objects:  27% (5/18)   \r",
      "Unpacking objects:  33% (6/18)   \r",
      "Unpacking objects:  38% (7/18)   \r",
      "Unpacking objects:  44% (8/18)   \r",
      "Unpacking objects:  50% (9/18)   \r",
      "Unpacking objects:  55% (10/18)   \r",
      "Unpacking objects:  61% (11/18)   \r",
      "Unpacking objects:  66% (12/18)   \r",
      "Unpacking objects:  72% (13/18)   \r",
      "Unpacking objects:  77% (14/18)   \r",
      "Unpacking objects:  83% (15/18)   \r",
      "Unpacking objects:  88% (16/18)   \r",
      "Unpacking objects:  94% (17/18)   \r",
      "Unpacking objects: 100% (18/18)   \r",
      "Unpacking objects: 100% (18/18), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/bojone/adafactor.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ABuaR7ZuZNCt"
   },
   "outputs": [],
   "source": [
    "from adafactor.adafactor import AdaFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "colab_type": "code",
    "id": "tndhxEA6O557",
    "outputId": "7869bd62-fabb-40aa-b60c-d7bc5a76d822"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 11/264 [>.............................] - ETA: 2:20 - loss: nan - accuracy: 0.4673"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-7f7d005f6d3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m                 initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=AdaFactor(1e-3),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "colab_type": "code",
    "id": "HoB35AEyVsC3",
    "outputId": "dfa36502-a63d-42b9-fb21-20864427e3b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 79/264 [=======>......................] - ETA: 1:07 - loss: nan - accuracy: 0.4909"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ef8550e8a401>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m                 initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "AdaFLR = extend_with_piecewise_linear_lr(AdaFactor, name='AdaFLR')\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=AdaFLR(learning_rate=1e-2, lr_schedule={\n",
    "        1000: 1,\n",
    "        3000: 0.1\n",
    "    }),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "\n",
    "#model.load_weights('best_model.weights')\n",
    "\n",
    "\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aUFqbhO44pmJ"
   },
   "source": [
    "#### 3.4 Adax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "3i2gz_fB4pEs",
    "outputId": "cb98fb87-f7d4-4123-e0e0-70a8fbff385c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'adax'...\n",
      "remote: Enumerating objects: 12, done.\u001b[K\n",
      "remote: Counting objects:   8% (1/12)\u001b[K\r",
      "remote: Counting objects:  16% (2/12)\u001b[K\r",
      "remote: Counting objects:  25% (3/12)\u001b[K\r",
      "remote: Counting objects:  33% (4/12)\u001b[K\r",
      "remote: Counting objects:  41% (5/12)\u001b[K\r",
      "remote: Counting objects:  50% (6/12)\u001b[K\r",
      "remote: Counting objects:  58% (7/12)\u001b[K\r",
      "remote: Counting objects:  66% (8/12)\u001b[K\r",
      "remote: Counting objects:  75% (9/12)\u001b[K\r",
      "remote: Counting objects:  83% (10/12)\u001b[K\r",
      "remote: Counting objects:  91% (11/12)\u001b[K\r",
      "remote: Counting objects: 100% (12/12)\u001b[K\r",
      "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
      "remote: Compressing objects:  11% (1/9)\u001b[K\r",
      "remote: Compressing objects:  22% (2/9)\u001b[K\r",
      "remote: Compressing objects:  33% (3/9)\u001b[K\r",
      "remote: Compressing objects:  44% (4/9)\u001b[K\r",
      "remote: Compressing objects:  55% (5/9)\u001b[K\r",
      "remote: Compressing objects:  66% (6/9)\u001b[K\r",
      "remote: Compressing objects:  77% (7/9)\u001b[K\r",
      "remote: Compressing objects:  88% (8/9)\u001b[K\r",
      "remote: Compressing objects: 100% (9/9)\u001b[K\r",
      "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
      "remote: Total 12 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects:   8% (1/12)   \r",
      "Unpacking objects:  16% (2/12)   \r",
      "Unpacking objects:  25% (3/12)   \r",
      "Unpacking objects:  33% (4/12)   \r",
      "Unpacking objects:  41% (5/12)   \r",
      "Unpacking objects:  50% (6/12)   \r",
      "Unpacking objects:  58% (7/12)   \r",
      "Unpacking objects:  66% (8/12)   \r",
      "Unpacking objects:  75% (9/12)   \r",
      "Unpacking objects:  83% (10/12)   \r",
      "Unpacking objects:  91% (11/12)   \r",
      "Unpacking objects: 100% (12/12)   \r",
      "Unpacking objects: 100% (12/12), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/bojone/adax.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JCpYFuAb41f2"
   },
   "outputs": [],
   "source": [
    "from adax.adax import AdaX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "id": "KDW2ElOT4C-w",
    "outputId": "4fe7dbb1-b388-496d-db2e-b5afb4c601cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "264/264 [==============================] - 151s 572ms/step - loss: 0.5147 - accuracy: 0.7696\n",
      "val_acc: 0.77546, best_val_acc: 0.77546, test_acc: 0.76883\n",
      "\n",
      "Epoch 2/5\n",
      "264/264 [==============================] - 157s 593ms/step - loss: 0.6946 - accuracy: 0.5071\n",
      "val_acc: 0.50876, best_val_acc: 0.77546, test_acc: 0.50166\n",
      "\n",
      "Epoch 3/5\n",
      "227/264 [========================>.....] - ETA: 21s - loss: 0.6946 - accuracy: 0.5162"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-3),  # 用足够小的学习率\n",
    "    optimizer=AdaX(1e-4),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "\n",
    "#model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JY1oI3DRTEM6"
   },
   "source": [
    "##### 3.4.1 线性分段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "iTgwYdDH9d8T",
    "outputId": "5b6d4b44-397b-43a5-d852-d5bac5eba5a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "264/264 [==============================] - 86s 327ms/step - loss: 0.0569 - accuracy: 0.9803\n",
      "val_acc: 0.87210, best_val_acc: 0.87210, test_acc: 0.87636\n",
      "\n",
      "Epoch 2/5\n",
      "264/264 [==============================] - 84s 317ms/step - loss: 0.1605 - accuracy: 0.9404\n",
      "val_acc: 0.90715, best_val_acc: 0.90715, test_acc: 0.90810\n",
      "\n",
      "Epoch 3/5\n",
      "264/264 [==============================] - 84s 317ms/step - loss: 0.2073 - accuracy: 0.9225\n",
      "val_acc: 0.88868, best_val_acc: 0.90715, test_acc: 0.87541\n",
      "\n",
      "Epoch 4/5\n",
      "264/264 [==============================] - 84s 317ms/step - loss: 0.3851 - accuracy: 0.8389\n",
      "val_acc: 0.84462, best_val_acc: 0.90715, test_acc: 0.83562\n",
      "\n",
      "Epoch 5/5\n",
      "264/264 [==============================] - 84s 317ms/step - loss: 0.3218 - accuracy: 0.8721\n",
      "val_acc: 0.85836, best_val_acc: 0.90715, test_acc: 0.85505\n",
      "\n",
      "final test acc: 0.855045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=AdaXLR(learning_rate=1e-3, lr_schedule={\n",
    "        1000: 1,\n",
    "        2000: 0.1\n",
    "    }),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "\n",
    "#model.load_weights('best_model.weights')\n",
    "AdaXLR = extend_with_piecewise_linear_lr(Adam, name='AdaXLR')\n",
    "\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-vPSOjtTOVIX"
   },
   "source": [
    "# part 4 错误分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "shMkU4LeMmr5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KODykQovORRn"
   },
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5U6-p8YkOWF8"
   },
   "outputs": [],
   "source": [
    "# 打印错误数\n",
    "num = 6\n",
    "tag = 0\n",
    "for x_true, y_true in test_generator:\n",
    "    tag +=1\n",
    "    if tag>num:\n",
    "      break\n",
    "    #print(x_true[0].shape)\n",
    "    y_pred = model.predict(x_true).argmax(axis=1)\n",
    "    y_true = y_true[:, 0]\n",
    "    #print(y_true)\n",
    "    #print(y_pred)\n",
    "    #error_pred = x_true[0][y_true!=y_pred]\n",
    "    error_ids = np.array(list(range(len(y_true))))[y_true!=y_pred]\n",
    "\n",
    "    print(error_ids)\n",
    "    for ids in error_ids:\n",
    "      print('text :{}\\npredict:{}, ture:{}\\n'.format(tokenizer.decode(x_true[0][ids]),y_pred[ids],y_true[ids]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "phkg2GGX0Hji"
   },
   "source": [
    "# 重启"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "rVwmoCTt0HDP",
    "outputId": "afa8beaf-8139-42ed-8868-655df09cc414"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'apt autoremove' to remove it.\n",
      "The following NEW packages will be installed:\n",
      "  psmisc\n",
      "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
      "Need to get 52.5 kB of archives.\n",
      "After this operation, 266 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 psmisc amd64 23.1-1ubuntu0.1 [52.5 kB]\n",
      "Fetched 52.5 kB in 0s (1,074 kB/s)\n",
      "Selecting previously unselected package psmisc.\n",
      "(Reading database ... 144465 files and directories currently installed.)\n",
      "Preparing to unpack .../psmisc_23.1-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking psmisc (23.1-1ubuntu0.1) ...\n",
      "Setting up psmisc (23.1-1ubuntu0.1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "/dev/nvidia0:          122m\n",
      "/dev/nvidiactl:        122m\n",
      "/dev/nvidia-uvm:       122m\n"
     ]
    }
   ],
   "source": [
    "# 重启\n",
    "!apt install psmisc\n",
    "!sudo fuser /dev/nvidia*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOYWkB-c0MrU"
   },
   "outputs": [],
   "source": [
    "! kill -9 122"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "compare_optimizer_albert_small.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
