{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ir_v-IHGL5w6"
   },
   "source": [
    "测试 albert_small 情感分类  \n",
    "https://github.com/bojone/bert4keras/blob/master/examples/task_sentiment_albert.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kXahXQ-sMIDN"
   },
   "source": [
    "# part1:配置环境 + 加载文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 710
    },
    "colab_type": "code",
    "id": "Pk5OZ22vM62G",
    "outputId": "fa7bec37-ae8d-48da-e9b0-abaf31487688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://www.github.com/bojone/bert4keras.git\n",
      "  Cloning https://www.github.com/bojone/bert4keras.git to /tmp/pip-req-build-wtazt4l8\n",
      "  Running command git clone -q https://www.github.com/bojone/bert4keras.git /tmp/pip-req-build-wtazt4l8\n",
      "Requirement already satisfied: keras<=2.3.1 in /usr/local/lib/python3.6/dist-packages (from bert4keras==0.8.3) (2.3.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (1.1.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (2.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (1.4.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (1.18.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (3.13)\n",
      "Building wheels for collected packages: bert4keras\n",
      "  Building wheel for bert4keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bert4keras: filename=bert4keras-0.8.3-cp36-none-any.whl size=41795 sha256=403804f3ee799ba5e6d95a02859c3bd0ef8bca1b52ab64e562968710f1beb10d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-o2rq9ix5/wheels/12/58/83/8ff5c864b80c860e6d9e9e0d90c04fafca05d01d21f9f6fcba\n",
      "Successfully built bert4keras\n",
      "Installing collected packages: bert4keras\n",
      "Successfully installed bert4keras-0.8.3\n",
      "2.2.0\n",
      "Tue Jul 21 12:00:45 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   39C    P0    61W / 149W |    130MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#! pip install keras_bert\n",
    "! pip install git+https://www.github.com/bojone/bert4keras.git\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(tf.__version__)\n",
    "tf.test.gpu_device_name()\n",
    "device_lib.list_local_devices()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2duJDYznMyoM"
   },
   "source": [
    "### 加载数据文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "gdiF0jadMzvb",
    "outputId": "5cbd5728-78bc-4748-9673-3250608d8e52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bert4keras'...\n",
      "remote: Enumerating objects: 5684, done.\u001b[K\n",
      "remote: Total 5684 (delta 0), reused 0 (delta 0), pack-reused 5684\u001b[K\n",
      "Receiving objects: 100% (5684/5684), 9.20 MiB | 23.27 MiB/s, done.\n",
      "Resolving deltas: 100% (3741/3741), done.\n",
      "Archive:  /content/bert4keras/examples/datasets/sentiment.zip\n",
      "   creating: /content/sample_data/sentiment/\n",
      "  inflating: /content/sample_data/sentiment/sentiment.test.data  \n",
      "  inflating: /content/sample_data/sentiment/sentiment.train.data  \n",
      "  inflating: /content/sample_data/sentiment/sentiment.valid.data  \n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/bojone/bert4keras.git\n",
    "! unzip -d '/content/sample_data' \"/content/bert4keras/examples/datasets/sentiment.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSoMYIdgMGWi"
   },
   "source": [
    "#### 1.1 加载ALbert_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N4NvJ1zNLi1z"
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/bojone/bert4keras.git\n",
    "! unzip -d '/content/sample_data' \"/content/bert4keras/examples/datasets/sentiment.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RD5YgLEwMbAz"
   },
   "source": [
    "#### 1.2 Albert_large_zh\n",
    "\n",
    "该版本不能被直接使用需要转换  \n",
    "https://github.com/bojone/albert_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8cQdyIxMF-S"
   },
   "outputs": [],
   "source": [
    "## 百度下载的 albert_large\n",
    "! unzip -o \"/content/drive/My Drive/local_copy/albert_large_google_zh.zip\" -d '/content/albert_large_google_zh'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DRy5MUYMMkfA"
   },
   "source": [
    "#### 1.3 Chinese-BERT-wwm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "3u7jIOpcLgw-",
    "outputId": "f862508b-d12d-44df-e3ca-3f5995dfb9d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/My Drive/Colab Notebooks/chinese_wwm_L-12_H-768_A-12.zip\n",
      "   creating: publish/\n",
      "  inflating: publish/vocab.txt       \n",
      "  inflating: publish/bert_model.ckpt.index  \n",
      "  inflating: publish/bert_model.ckpt.data-00000-of-00001  \n",
      "  inflating: publish/bert_config.json  \n",
      "  inflating: publish/bert_model.ckpt.meta  \n"
     ]
    }
   ],
   "source": [
    "# 加载drive中的bert checkpoint\n",
    "#! wget https://github.com/ymcui/Chinese-BERT-wwm\n",
    "! unzip \"/content/drive/My Drive/Colab Notebooks/chinese_wwm_L-12_H-768_A-12.zip\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-xj6GImvNAL4"
   },
   "source": [
    "# part2 配置全局参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OX4N6WqVNVv1",
    "outputId": "2e6f5aab-0774-4e5d-a37f-d071430dfbf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import codecs\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from bert4keras.backend import keras, set_gelu\n",
    "from bert4keras.tokenizers import Tokenizer\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.optimizers import Adam, extend_with_piecewise_linear_lr\n",
    "from bert4keras.snippets import sequence_padding, DataGenerator\n",
    "from bert4keras.snippets import open\n",
    "from keras.layers import Lambda, Dense\n",
    "from bert4keras.optimizers import *\n",
    "\n",
    "set_gelu('tanh')  # 切换gelu版本\n",
    "\n",
    "num_classes = 2\n",
    "maxlen = 128\n",
    "batch_size = 64\n",
    "# 1 训练数据文件路径\n",
    "data_dir = \"/content/sample_data/sentiment\"\n",
    "train_data_dir = data_dir + \"/sentiment.train.data\"\n",
    "valid_data_dir = data_dir + \"/sentiment.valid.data\"\n",
    "test_data_dir = data_dir + \"/sentiment.test.data\"\n",
    "\n",
    "print(os.path.exists(train_data_dir))\n",
    "\n",
    "# 3 训练模型文件路径\n",
    "checkpoint_dir = 'checkpoint/subject_extract2'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "# 4 结果输出路径    \n",
    "outputdir = '/content/drive/My Drive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P6i5jLTAQTIy"
   },
   "source": [
    "### 2.1 albert_small_google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQyaffczQTvd"
   },
   "outputs": [],
   "source": [
    "\n",
    "config_path = '/content/albert_small_zh_google/albert_config_small_google.json'\n",
    "checkpoint_path = '/content/albert_small_zh_google/albert_model.ckpt'\n",
    "dict_path = '/content/albert_small_zh_google/vocab.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UUeM6Rb7Qfb4"
   },
   "source": [
    "### 2.2 albert_large_google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k78JTxt0Qd71"
   },
   "outputs": [],
   "source": [
    "model_dir = \"/content/albert_large_google_zh/albert_large_google_zh\"\n",
    "config_path = model_dir + '/albert_config.json'\n",
    "checkpoint_path = model_dir + '/albert_model.ckpt'\n",
    "dict_path = model_dir + '/vocab.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MoPb3RlRQjmH"
   },
   "source": [
    "### 2.3 bert_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VgLTSoPvQ1wL",
    "outputId": "456b6c63-9f48-4168-a7da-82234d2a788e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint path :  True\n"
     ]
    }
   ],
   "source": [
    "config_path = './publish/bert_config.json'\n",
    "checkpoint_path = './publish/bert_model.ckpt'\n",
    "dict_path = './publish/vocab.txt'\n",
    " \n",
    "print('load checkpoint path : ',os.path.exists(config_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vGC-5O-pN3Ll"
   },
   "source": [
    "# part 3 模型部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ij8GK-g6NYZj"
   },
   "source": [
    "### 数据构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2rBLHaIDNZLX"
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_data(filename):\n",
    "    D = []\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        for l in f:\n",
    "            text, label = l.strip().split('\\t')\n",
    "            D.append((text, int(label)))\n",
    "    return D\n",
    "\n",
    "\n",
    "# 加载数据集\n",
    "train_data = load_data(train_data_dir)\n",
    "valid_data = load_data(valid_data_dir)\n",
    "test_data = load_data(test_data_dir)\n",
    "\n",
    "# 建立分词器\n",
    "tokenizer = Tokenizer(dict_path, do_lower_case=True)\n",
    "\n",
    "class data_generator(DataGenerator):\n",
    "    \"\"\"数据生成器\n",
    "    \"\"\"\n",
    "    def __iter__(self, random=False):\n",
    "        batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n",
    "        for is_end, (text, label) in self.sample(random):\n",
    "            token_ids, segment_ids = tokenizer.encode(text, maxlen=maxlen)\n",
    "            batch_token_ids.append(token_ids)\n",
    "            batch_segment_ids.append(segment_ids)\n",
    "            batch_labels.append([label])\n",
    "            if len(batch_token_ids) == self.batch_size or is_end:\n",
    "                batch_token_ids = sequence_padding(batch_token_ids)\n",
    "                batch_segment_ids = sequence_padding(batch_segment_ids)\n",
    "                batch_labels = sequence_padding(batch_labels)\n",
    "                yield [batch_token_ids, batch_segment_ids], batch_labels\n",
    "                batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n",
    "\n",
    "# 转换数据集\n",
    "train_generator = data_generator(train_data, batch_size)\n",
    "valid_generator = data_generator(valid_data, batch_size)\n",
    "test_generator = data_generator(test_data, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "id": "FBHfC8x_RtCK",
    "outputId": "e7dd6917-0f8f-4947-ccc5-dda63bd7fd8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids : [ 101 5885 4281 1920 3362 5108 8013 3362 3171 2682 6629 7770  676 1939\n",
      " 3159 4638 6929 3667 3189 2094 8080  102    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0] \n",
      "text:蒙牛大果粒！果断想起高三奋斗的那段日子～\n",
      "label:[1]\n"
     ]
    }
   ],
   "source": [
    "# 查看数据\n",
    "tag = 0\n",
    "for i in train_generator.forfit():\n",
    "  tag +=1\n",
    "  if tag>1:\n",
    "    break\n",
    "  #print(i,len(i))\n",
    "  #print(i[0],'\\n',i[1])\n",
    "  #print(i[0][0],'\\n',i[0][0].shape)\n",
    "  #print(i[0][1],'\\n',i[0][1].shape)\n",
    "  #print(i[1],'\\n',i[1].shape)\n",
    "  print('ids : {} \\ntext:{}\\nlabel:{}'.format(i[0][0][0],tokenizer.decode(i[0][0][0]),i[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DB0scGYCNteG"
   },
   "source": [
    "###  模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxuxf4tZSqOS"
   },
   "source": [
    "## ALBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MfxH2ic9Nm9E"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 加载预训练模型\n",
    "## return_keras_model=False 不训练层\n",
    "bert = build_transformer_model(\n",
    "    config_path=config_path,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    model='albert',\n",
    "    return_keras_model=False,\n",
    ")\n",
    "\n",
    "output = Lambda(lambda x: x[:, 0], name='CLS-token')(bert.model.output)#只取cls值\n",
    "output = Dense(\n",
    "    units=num_classes,\n",
    "    activation='softmax',\n",
    "    kernel_initializer=bert.initializer\n",
    ")(output)\n",
    "\n",
    "model = keras.models.Model(bert.model.input, output)\n",
    "model.summary()\n",
    "\n",
    "# 派生为带分段线性学习率的优化器。\n",
    "# 其中name参数可选，但最好填入，以区分不同的派生优化器。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PuqSRqxvSvuy"
   },
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ih5LU777S6Xk",
    "outputId": "8878a6c9-a37c-4ec3-b070-73ad427618eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (Embedding)     (None, None, 768)    16226304    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, None, 768)    393216      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          \n",
      "                                                                 Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
      "                                                                 Transformer-0-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Norm  (None, None, 768)    1536        Transformer-0-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
      "                                                                 Transformer-1-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Norm  (None, None, 768)    1536        Transformer-1-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
      "                                                                 Transformer-2-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Norm  (None, None, 768)    1536        Transformer-2-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
      "                                                                 Transformer-3-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Norm  (None, None, 768)    1536        Transformer-3-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "CLS-token (Lambda)              (None, 768)          0           Transformer-3-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_532 (Dense)               (None, 2)            1538        CLS-token[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 44,975,618\n",
      "Trainable params: 44,975,618\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert = build_transformer_model(\n",
    "    config_path=config_path,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    return_keras_model=True,\n",
    ")\n",
    "layer_name = 'Transformer-3-FeedForward-Norm'                                    \n",
    "\n",
    "\n",
    "output = Lambda(lambda x: x[:, 0], name='CLS-token')(bert.get_layer(layer_name).output)#只取cls值\n",
    "output = Dense(\n",
    "    units=num_classes,\n",
    "    activation='softmax',\n",
    "    kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.02)\n",
    ")(output)\n",
    "\n",
    "model = keras.models.Model(bert.input, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZpGsJOzeRbFb"
   },
   "source": [
    "### optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B5uN4c9EOx1E"
   },
   "source": [
    "#### 3.1 线性Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uVSKVOFFPWlR"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QerDtEgUPO17"
   },
   "source": [
    "#### 3.2 线性AdamLR\n",
    "可以分段调控 ，线性变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ICvetwD7Ou2i"
   },
   "outputs": [],
   "source": [
    "AdamLR = extend_with_piecewise_linear_lr(Adam, name='AdamLR')\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    optimizer=AdamLR(learning_rate=1e-4, lr_schedule={\n",
    "        1000: 1,\n",
    "        2000: 0.1\n",
    "    }),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3IMMmTWiO9Ld"
   },
   "source": [
    "#### 3.3 线性AdaFactor\n",
    "这个优化器lr batch_size 需要大一点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tndhxEA6O557"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-3),  # 用足够小的学习率\n",
    "    optimizer=AdaFactor(learning_rate=1e-3),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1W14hKLNOBsR"
   },
   "source": [
    "### callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0yr4SHR4OFYG"
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(data):\n",
    "    total, right = 0., 0.\n",
    "    for x_true, y_true in data:\n",
    "        y_pred = model.predict(x_true).argmax(axis=1)\n",
    "        y_true = y_true[:, 0]\n",
    "        total += len(y_true)\n",
    "        right += (y_true == y_pred).sum()\n",
    "    return right / total\n",
    "\n",
    "\n",
    "class Evaluator(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.best_val_acc = 0.\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_acc = evaluate(valid_generator)\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            model.save_weights('best_model.weights')\n",
    "        test_acc = evaluate(test_generator)\n",
    "        print(\n",
    "            u'val_acc: %.5f, best_val_acc: %.5f, test_acc: %.5f\\n' %\n",
    "            (val_acc, self.best_val_acc, test_acc)\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KODykQovORRn"
   },
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "Awhd8y8IOOM3",
    "outputId": "640ebfda-aa1c-439d-b4ac-10252f5a198a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "264/264 [==============================] - 257s 973ms/step - loss: 0.2609 - accuracy: 0.8939\n",
      "val_acc: 0.92373, best_val_acc: 0.92373, test_acc: 0.92610\n",
      "\n",
      "Epoch 2/10\n",
      "264/264 [==============================] - 255s 964ms/step - loss: 0.1196 - accuracy: 0.9569\n",
      "val_acc: 0.93842, best_val_acc: 0.93842, test_acc: 0.94694\n",
      "\n",
      "Epoch 3/10\n",
      "264/264 [==============================] - 255s 964ms/step - loss: 0.0604 - accuracy: 0.9787\n",
      "val_acc: 0.92563, best_val_acc: 0.93842, test_acc: 0.93036\n",
      "\n",
      "Epoch 4/10\n",
      "264/264 [==============================] - 255s 965ms/step - loss: 0.0376 - accuracy: 0.9873\n",
      "val_acc: 0.94363, best_val_acc: 0.94363, test_acc: 0.94410\n",
      "\n",
      "Epoch 5/10\n",
      "264/264 [==============================] - 255s 964ms/step - loss: 0.0271 - accuracy: 0.9909\n",
      "val_acc: 0.93558, best_val_acc: 0.94363, test_acc: 0.94173\n",
      "\n",
      "Epoch 6/10\n",
      "264/264 [==============================] - 255s 965ms/step - loss: 0.0219 - accuracy: 0.9922\n",
      "val_acc: 0.94315, best_val_acc: 0.94363, test_acc: 0.93984\n",
      "\n",
      "Epoch 7/10\n",
      "264/264 [==============================] - 255s 965ms/step - loss: 0.0157 - accuracy: 0.9944\n",
      "val_acc: 0.94458, best_val_acc: 0.94458, test_acc: 0.94505\n",
      "\n",
      "Epoch 8/10\n",
      "264/264 [==============================] - 255s 964ms/step - loss: 0.0164 - accuracy: 0.9943\n",
      "val_acc: 0.94173, best_val_acc: 0.94458, test_acc: 0.94505\n",
      "\n",
      "Epoch 9/10\n",
      "264/264 [==============================] - 255s 964ms/step - loss: 0.0207 - accuracy: 0.9929\n",
      "val_acc: 0.94126, best_val_acc: 0.94458, test_acc: 0.93463\n",
      "\n",
      "Epoch 10/10\n",
      " 70/264 [======>.......................] - ETA: 3:07 - loss: 0.0131 - accuracy: 0.9958"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-vPSOjtTOVIX"
   },
   "source": [
    "# part 4 错误分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5U6-p8YkOWF8"
   },
   "outputs": [],
   "source": [
    "# 打印错误数\n",
    "num = 6\n",
    "tag = 0\n",
    "for x_true, y_true in test_generator:\n",
    "    tag +=1\n",
    "    if tag>num:\n",
    "      break\n",
    "    #print(x_true[0].shape)\n",
    "    y_pred = model.predict(x_true).argmax(axis=1)\n",
    "    y_true = y_true[:, 0]\n",
    "    #print(y_true)\n",
    "    #print(y_pred)\n",
    "    #error_pred = x_true[0][y_true!=y_pred]\n",
    "    error_ids = np.array(list(range(len(y_true))))[y_true!=y_pred]\n",
    "\n",
    "    print(error_ids)\n",
    "    for ids in error_ids:\n",
    "      print('text :{}\\npredict:{}, ture:{}\\n'.format(tokenizer.decode(x_true[0][ids]),y_pred[ids],y_true[ids]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "compare_optimizer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
