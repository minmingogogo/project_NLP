{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ir_v-IHGL5w6"
   },
   "source": [
    "测试 albert_small 情感分类  \n",
    "https://github.com/bojone/bert4keras/blob/master/examples/task_sentiment_albert.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kXahXQ-sMIDN"
   },
   "source": [
    "# part1:配置环境 + 加载文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "colab_type": "code",
    "id": "Pk5OZ22vM62G",
    "outputId": "57a412e9-02bf-410e-e20e-4acaa6949108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://www.github.com/bojone/bert4keras.git\n",
      "  Cloning https://www.github.com/bojone/bert4keras.git to /tmp/pip-req-build-ebxntx5t\n",
      "  Running command git clone -q https://www.github.com/bojone/bert4keras.git /tmp/pip-req-build-ebxntx5t\n",
      "Requirement already satisfied (use --upgrade to upgrade): bert4keras==0.8.3 from git+https://www.github.com/bojone/bert4keras.git in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: keras<=2.3.1 in /usr/local/lib/python3.6/dist-packages (from bert4keras==0.8.3) (2.3.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (1.1.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (1.18.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (3.13)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras==0.8.3) (1.0.8)\n",
      "Building wheels for collected packages: bert4keras\n",
      "  Building wheel for bert4keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bert4keras: filename=bert4keras-0.8.3-cp36-none-any.whl size=41795 sha256=a1d8f6db1cf8c45d26f58f550662fba339a2a26ad8232f93e85f09afe6d9a6ee\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-a22yln38/wheels/12/58/83/8ff5c864b80c860e6d9e9e0d90c04fafca05d01d21f9f6fcba\n",
      "Successfully built bert4keras\n",
      "2.2.0\n",
      "Wed Jul 22 01:54:50 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   57C    P0    62W / 149W |    643MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#! pip install keras_bert\n",
    "! pip install git+https://www.github.com/bojone/bert4keras.git\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(tf.__version__)\n",
    "tf.test.gpu_device_name()\n",
    "device_lib.list_local_devices()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "OurdG48h8B0L",
    "outputId": "a6e1dd80-b73f-45b4-9477-2053950fdf10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2duJDYznMyoM"
   },
   "source": [
    "### 加载数据文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "gdiF0jadMzvb",
    "outputId": "5966d6c2-fb4d-4e8b-ac36-240d51226653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bert4keras'...\n",
      "remote: Enumerating objects: 5684, done.\u001b[K\n",
      "remote: Total 5684 (delta 0), reused 0 (delta 0), pack-reused 5684\u001b[K\n",
      "Receiving objects: 100% (5684/5684), 9.20 MiB | 5.66 MiB/s, done.\n",
      "Resolving deltas: 100% (3741/3741), done.\n",
      "Archive:  /content/bert4keras/examples/datasets/sentiment.zip\n",
      "   creating: /content/sample_data/sentiment/\n",
      "  inflating: /content/sample_data/sentiment/sentiment.test.data  \n",
      "  inflating: /content/sample_data/sentiment/sentiment.train.data  \n",
      "  inflating: /content/sample_data/sentiment/sentiment.valid.data  \n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/bojone/bert4keras.git\n",
    "! unzip -d '/content/sample_data' \"/content/bert4keras/examples/datasets/sentiment.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSoMYIdgMGWi"
   },
   "source": [
    "#### 1.1 加载ALbert_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "a-d9Mvx4q40u",
    "outputId": "8f0c5055-00a4-4ae8-c88b-7a5955877e10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-21 15:14:32--  https://storage.googleapis.com/albert_zh/albert_small_zh_google.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 74.125.195.128, 142.250.107.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 53458815 (51M) [application/zip]\n",
      "Saving to: ‘albert_small_zh_google.zip’\n",
      "\n",
      "albert_small_zh_goo 100%[===================>]  50.98M  32.2MB/s    in 1.6s    \n",
      "\n",
      "2020-07-21 15:14:34 (32.2 MB/s) - ‘albert_small_zh_google.zip’ saved [53458815/53458815]\n",
      "\n",
      "Archive:  /content/albert_small_zh_google.zip\n",
      "  inflating: /content/albert_small_zh_google/albert_config_small_google.json  \n",
      "  inflating: /content/albert_small_zh_google/albert_model.ckpt.data-00000-of-00001  \n",
      "  inflating: /content/albert_small_zh_google/albert_model.ckpt.index  \n",
      "  inflating: /content/albert_small_zh_google/albert_model.ckpt.meta  \n",
      "  inflating: /content/albert_small_zh_google/checkpoint  \n",
      "  inflating: /content/albert_small_zh_google/vocab.txt  \n"
     ]
    }
   ],
   "source": [
    "! wget https://storage.googleapis.com/albert_zh/albert_small_zh_google.zip\n",
    "! unzip -o \"/content/albert_small_zh_google.zip\" -d '/content/albert_small_zh_google'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RD5YgLEwMbAz"
   },
   "source": [
    "#### 1.2 Albert_large_zh\n",
    "\n",
    "该版本不能被直接使用需要转换  \n",
    "https://github.com/bojone/albert_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "P8cQdyIxMF-S",
    "outputId": "595cc20b-f323-44a2-9a06-1115391d2174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/My Drive/local_copy/albert_large_google_zh.zip\n",
      "   creating: /content/albert_large_google_zh/albert_large_google_zh/\n",
      "  inflating: /content/albert_large_google_zh/albert_large_google_zh/albert_model.ckpt.data-00000-of-00001  \n",
      "  inflating: /content/albert_large_google_zh/albert_large_google_zh/albert_model.ckpt.index  \n",
      "  inflating: /content/albert_large_google_zh/albert_large_google_zh/checkpoint  \n",
      "  inflating: /content/albert_large_google_zh/albert_large_google_zh/vocab.txt  \n",
      "  inflating: /content/albert_large_google_zh/albert_large_google_zh/albert_config.json  \n"
     ]
    }
   ],
   "source": [
    "## 百度下载的 albert_large\n",
    "! unzip -o \"/content/drive/My Drive/local_copy/albert_large_google_zh.zip\" -d '/content/albert_large_google_zh'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DRy5MUYMMkfA"
   },
   "source": [
    "#### 1.3 Chinese-BERT-wwm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "3u7jIOpcLgw-",
    "outputId": "9963867e-9732-4ed7-b73d-c5d8dc4cf440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/My Drive/Colab Notebooks/chinese_wwm_L-12_H-768_A-12.zip\n",
      "   creating: publish/\n",
      "  inflating: publish/vocab.txt       \n",
      "  inflating: publish/bert_model.ckpt.index  \n",
      "  inflating: publish/bert_model.ckpt.data-00000-of-00001  \n",
      "  inflating: publish/bert_config.json  \n",
      "  inflating: publish/bert_model.ckpt.meta  \n"
     ]
    }
   ],
   "source": [
    "# 加载drive中的bert checkpoint\n",
    "#! wget https://github.com/ymcui/Chinese-BERT-wwm\n",
    "! unzip \"/content/drive/My Drive/Colab Notebooks/chinese_wwm_L-12_H-768_A-12.zip\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-xj6GImvNAL4"
   },
   "source": [
    "# part2 配置全局参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "OX4N6WqVNVv1",
    "outputId": "81920926-8d06-4f87-a119-1cd7a5a0254c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import codecs\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from bert4keras.backend import keras, set_gelu\n",
    "from bert4keras.tokenizers import Tokenizer\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.optimizers import Adam, extend_with_piecewise_linear_lr\n",
    "from bert4keras.snippets import sequence_padding, DataGenerator\n",
    "from bert4keras.snippets import open\n",
    "from keras.layers import Lambda, Dense\n",
    "from bert4keras.optimizers import *\n",
    "\n",
    "set_gelu('tanh')  # 切换gelu版本\n",
    "\n",
    "num_classes = 2\n",
    "maxlen = 128\n",
    "batch_size = 64\n",
    "# 1 训练数据文件路径\n",
    "data_dir = \"/content/sample_data/sentiment\"\n",
    "train_data_dir = data_dir + \"/sentiment.train.data\"\n",
    "valid_data_dir = data_dir + \"/sentiment.valid.data\"\n",
    "test_data_dir = data_dir + \"/sentiment.test.data\"\n",
    "\n",
    "print(os.path.exists(train_data_dir))\n",
    "\n",
    "# 3 训练模型文件路径\n",
    "checkpoint_dir = 'checkpoint/subject_extract2'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "# 4 结果输出路径    \n",
    "outputdir = '/content/drive/My Drive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P6i5jLTAQTIy"
   },
   "source": [
    "### 2.1 albert_small_google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQyaffczQTvd"
   },
   "outputs": [],
   "source": [
    "\n",
    "config_path = '/content/albert_small_zh_google/albert_config_small_google.json'\n",
    "checkpoint_path = '/content/albert_small_zh_google/albert_model.ckpt'\n",
    "dict_path = '/content/albert_small_zh_google/vocab.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UUeM6Rb7Qfb4"
   },
   "source": [
    "### 2.2 albert_large_google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k78JTxt0Qd71"
   },
   "outputs": [],
   "source": [
    "model_dir = \"/content/albert_large_google_zh/albert_large_google_zh\"\n",
    "config_path = model_dir + '/albert_config.json'\n",
    "checkpoint_path = model_dir + '/albert_model.ckpt'\n",
    "dict_path = model_dir + '/vocab.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MoPb3RlRQjmH"
   },
   "source": [
    "### 2.3 bert_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VgLTSoPvQ1wL",
    "outputId": "314b5025-fab8-4d85-cc90-80120b4bb2c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint path :  True\n"
     ]
    }
   ],
   "source": [
    "config_path = './publish/bert_config.json'\n",
    "checkpoint_path = './publish/bert_model.ckpt'\n",
    "dict_path = './publish/vocab.txt'\n",
    " \n",
    "print('load checkpoint path : ',os.path.exists(config_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vGC-5O-pN3Ll"
   },
   "source": [
    "# part 3 模型部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ij8GK-g6NYZj"
   },
   "source": [
    "## 数据构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2rBLHaIDNZLX"
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_data(filename):\n",
    "    D = []\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        for l in f:\n",
    "            text, label = l.strip().split('\\t')\n",
    "            D.append((text, int(label)))\n",
    "    return D\n",
    "\n",
    "\n",
    "# 加载数据集\n",
    "train_data = load_data(train_data_dir)\n",
    "valid_data = load_data(valid_data_dir)\n",
    "test_data = load_data(test_data_dir)\n",
    "\n",
    "# 建立分词器\n",
    "tokenizer = Tokenizer(dict_path, do_lower_case=True)\n",
    "\n",
    "class data_generator(DataGenerator):\n",
    "    \"\"\"数据生成器\n",
    "    \"\"\"\n",
    "    def __iter__(self, random=False):\n",
    "        batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n",
    "        for is_end, (text, label) in self.sample(random):\n",
    "            token_ids, segment_ids = tokenizer.encode(text, maxlen=maxlen)\n",
    "            batch_token_ids.append(token_ids)\n",
    "            batch_segment_ids.append(segment_ids)\n",
    "            batch_labels.append([label])\n",
    "            if len(batch_token_ids) == self.batch_size or is_end:\n",
    "                batch_token_ids = sequence_padding(batch_token_ids)\n",
    "                batch_segment_ids = sequence_padding(batch_segment_ids)\n",
    "                batch_labels = sequence_padding(batch_labels)\n",
    "                yield [batch_token_ids, batch_segment_ids], batch_labels\n",
    "                batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n",
    "\n",
    "# 转换数据集\n",
    "train_generator = data_generator(train_data, batch_size)\n",
    "valid_generator = data_generator(valid_data, batch_size)\n",
    "test_generator = data_generator(test_data, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "id": "FBHfC8x_RtCK",
    "outputId": "2adab43d-4bd8-43a7-e7c5-ad37be8b0e5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids : [ 101  976  711 6585 4277 2797 3322 8024 2825 3318 3221  676 3215 4638\n",
      " 8024 2418 6421 3766 6574 7030  677 4638 7309 7579  511  852 1216 5543\n",
      " 6814 2208 8024 6825 5408 1355 4764  928 6963 3766 3300 8024 4385 1762\n",
      " 1525  702 2797 3322 3766 3300 6821  702 3297 1825 3315 4638 8043  738\n",
      "  679 3118 2898 2506  928 8013 4510 6413 5946 5042 1296 8024 5468 5143\n",
      "  782 4638  928 2622 3187 3791 3924 1217 1914  763 8013 2823 6629 3341\n",
      "  738 3683 6772 7937 4172 8013  102    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0] \n",
      "text:做为贴牌手机，技术是三星的，应该没质量上的问题。但功能过少，连群发短信都没有，现在哪个手机没有这个最基本的？也不支持彩信！电话薄简单，联系人的信息无法添加多些！找起来也比较麻烦！\n",
      "label:[0]\n"
     ]
    }
   ],
   "source": [
    "# 查看数据\n",
    "tag = 0\n",
    "for i in train_generator.forfit():\n",
    "  tag +=1\n",
    "  if tag>1:\n",
    "    break\n",
    "  #print(i,len(i))\n",
    "  #print(i[0],'\\n',i[1])\n",
    "  #print(i[0][0],'\\n',i[0][0].shape)\n",
    "  #print(i[0][1],'\\n',i[0][1].shape)\n",
    "  #print(i[1],'\\n',i[1].shape)\n",
    "  print('ids : {} \\ntext:{}\\nlabel:{}'.format(i[0][0][0],tokenizer.decode(i[0][0][0]),i[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DB0scGYCNteG"
   },
   "source": [
    "##  模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxuxf4tZSqOS"
   },
   "source": [
    "### ALBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MfxH2ic9Nm9E"
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "# 加载预训练模型\n",
    "## return_keras_model=False 不训练层\n",
    "bert = build_transformer_model(\n",
    "    config_path=config_path,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    model='albert',\n",
    "    return_keras_model=False,\n",
    ")\n",
    "\n",
    "output = Lambda(lambda x: x[:, 0], name='CLS-token')(bert.model.output)#只取cls值\n",
    "output = Dense(\n",
    "    units=num_classes,\n",
    "    activation='softmax',\n",
    "    kernel_initializer=bert.initializer\n",
    ")(output)\n",
    "\n",
    "model = keras.models.Model(bert.model.input, output)\n",
    "model.summary()\n",
    "\n",
    "# 派生为带分段线性学习率的优化器。\n",
    "# 其中name参数可选，但最好填入，以区分不同的派生优化器。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PuqSRqxvSvuy"
   },
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ih5LU777S6Xk",
    "outputId": "5243c2ec-d1fd-4fae-ceed-c5a902451dd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (Embedding)     (None, None, 768)    16226304    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, None, 768)    393216      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          \n",
      "                                                                 Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
      "                                                                 Transformer-0-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Norm  (None, None, 768)    1536        Transformer-0-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
      "                                                                 Transformer-1-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Norm  (None, None, 768)    1536        Transformer-1-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
      "                                                                 Transformer-2-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Norm  (None, None, 768)    1536        Transformer-2-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
      "                                                                 Transformer-3-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Norm  (None, None, 768)    1536        Transformer-3-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "CLS-token (Lambda)              (None, 768)          0           Transformer-3-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 2)            1538        CLS-token[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 44,975,618\n",
      "Trainable params: 44,975,618\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "bert = build_transformer_model(\n",
    "    config_path=config_path,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    return_keras_model=True,\n",
    ")\n",
    "layer_name = 'Transformer-3-FeedForward-Norm'                                    \n",
    "\n",
    "\n",
    "output = Lambda(lambda x: x[:, 0], name='CLS-token')(bert.get_layer(layer_name).output)#只取cls值\n",
    "output = Dense(\n",
    "    units=num_classes,\n",
    "    activation='softmax',\n",
    "    kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.02)\n",
    ")(output)\n",
    "\n",
    "model = keras.models.Model(bert.input, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1W14hKLNOBsR"
   },
   "source": [
    "### callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0yr4SHR4OFYG"
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(data):\n",
    "    total, right = 0., 0.\n",
    "    for x_true, y_true in data:\n",
    "        y_pred = model.predict(x_true).argmax(axis=1)\n",
    "        y_true = y_true[:, 0]\n",
    "        total += len(y_true)\n",
    "        right += (y_true == y_pred).sum()\n",
    "    return right / total\n",
    "\n",
    "\n",
    "class Evaluator(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.best_val_acc = 0.\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_acc = evaluate(valid_generator)\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            model.save_weights('best_model.weights')\n",
    "        test_acc = evaluate(test_generator)\n",
    "        print(\n",
    "            u'val_acc: %.5f, best_val_acc: %.5f, test_acc: %.5f\\n' %\n",
    "            (val_acc, self.best_val_acc, test_acc)\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZpGsJOzeRbFb"
   },
   "source": [
    "### Optimizer  \n",
    "    Adam AdaFactor AdaX   \n",
    "\n",
    "优秀的老手用SGD精调"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-q0bzcFq9uuI"
   },
   "source": [
    "### 优化器策略  \n",
    "#### 1 权重衰减\n",
    "    extend_with_weight_decay  \n",
    "\n",
    "#### 2 层自适应学习率\n",
    "    extend_with_layer_adaptation\n",
    "\n",
    "#### 3 分段线性学习率\n",
    "    extend_with_piecewise_linear_lr  \n",
    "\n",
    "#### 4 梯度累积\n",
    "    extend_with_gradient_accumulation  \n",
    "\n",
    "#### 5 带有look ahead的优化器   \n",
    "    extend_with_lookahead  \n",
    "https://arxiv.org/abs/1907.08610\n",
    "steps_per_slow_update: 即论文中的k；\n",
    "slow_step_size: 即论文中的alpha。  \n",
    "知乎讨论，与本次试验感觉差不多  \n",
    "https://www.zhihu.com/question/336837858  \n",
    "\n",
    "#### 6 懒惰更新 \n",
    "    extend_with_lazy_optimization   \n",
    "使得部分权重（尤其是embedding）只有在梯度不等于0时\n",
    "        才发生更新。  \n",
    "\n",
    "#### 7 EMA（权重滑动平均）\n",
    "    extend_with_exponential_moving_average  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B5uN4c9EOx1E"
   },
   "source": [
    "#### 3.1 Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "colab_type": "code",
    "id": "uVSKVOFFPWlR",
    "outputId": "698f8bd6-439c-4294-f2d6-d17383b6c7e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "264/264 [==============================] - 85s 322ms/step - loss: 0.0852 - accuracy: 0.9702\n",
      "val_acc: 0.93321, best_val_acc: 0.93321, test_acc: 0.93321\n",
      "\n",
      "Epoch 2/10\n",
      "264/264 [==============================] - 83s 313ms/step - loss: 0.0501 - accuracy: 0.9826\n",
      "val_acc: 0.94126, best_val_acc: 0.94126, test_acc: 0.93321\n",
      "\n",
      "Epoch 3/10\n",
      "264/264 [==============================] - 82s 312ms/step - loss: 0.0344 - accuracy: 0.9876\n",
      "val_acc: 0.94458, best_val_acc: 0.94458, test_acc: 0.93605\n",
      "\n",
      "Epoch 4/10\n",
      "264/264 [==============================] - 82s 312ms/step - loss: 0.0272 - accuracy: 0.9898\n",
      "val_acc: 0.93937, best_val_acc: 0.94458, test_acc: 0.93937\n",
      "\n",
      "Epoch 5/10\n",
      "264/264 [==============================] - 83s 313ms/step - loss: 0.0307 - accuracy: 0.9890\n",
      "val_acc: 0.93984, best_val_acc: 0.94458, test_acc: 0.93842\n",
      "\n",
      "Epoch 6/10\n",
      "264/264 [==============================] - 83s 313ms/step - loss: 0.0188 - accuracy: 0.9937\n",
      "val_acc: 0.94173, best_val_acc: 0.94458, test_acc: 0.94837\n",
      "\n",
      "Epoch 7/10\n",
      "264/264 [==============================] - 83s 313ms/step - loss: 0.0166 - accuracy: 0.9944\n",
      "val_acc: 0.93321, best_val_acc: 0.94458, test_acc: 0.93889\n",
      "\n",
      "Epoch 8/10\n",
      "264/264 [==============================] - 83s 313ms/step - loss: 0.0178 - accuracy: 0.9937\n",
      "val_acc: 0.93842, best_val_acc: 0.94458, test_acc: 0.94268\n",
      "\n",
      "Epoch 9/10\n",
      "264/264 [==============================] - 83s 313ms/step - loss: 0.0168 - accuracy: 0.9939\n",
      "val_acc: 0.94221, best_val_acc: 0.94458, test_acc: 0.94694\n",
      "\n",
      "Epoch 10/10\n",
      "264/264 [==============================] - 83s 313ms/step - loss: 0.0121 - accuracy: 0.9958\n",
      "val_acc: 0.94126, best_val_acc: 0.94458, test_acc: 0.93510\n",
      "\n",
      "final test acc: 0.936049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "evaluator = Evaluator()\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QerDtEgUPO17"
   },
   "source": [
    "##### 3.1.1 线性AdamLR\n",
    "可以分段调控 ，线性变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "4GCb0DBakeg8",
    "outputId": "e4ff209b-cfb2-494f-8feb-b09caf8d2722"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "264/264 [==============================] - 80s 302ms/step - loss: 0.4689 - accuracy: 0.7638\n",
      "val_acc: 0.88726, best_val_acc: 0.88726, test_acc: 0.88205\n",
      "\n",
      "Epoch 2/5\n",
      "264/264 [==============================] - 80s 304ms/step - loss: 0.2379 - accuracy: 0.9106\n",
      "val_acc: 0.92468, best_val_acc: 0.92468, test_acc: 0.91757\n",
      "\n",
      "Epoch 3/5\n",
      "264/264 [==============================] - 81s 306ms/step - loss: 0.1656 - accuracy: 0.9418\n",
      "val_acc: 0.93368, best_val_acc: 0.93368, test_acc: 0.92752\n",
      "\n",
      "Epoch 4/5\n",
      "264/264 [==============================] - 81s 306ms/step - loss: 0.1188 - accuracy: 0.9582\n",
      "val_acc: 0.93321, best_val_acc: 0.93368, test_acc: 0.92942\n",
      "\n",
      "Epoch 5/5\n",
      "264/264 [==============================] - 81s 307ms/step - loss: 0.0707 - accuracy: 0.9765\n",
      "val_acc: 0.94173, best_val_acc: 0.94173, test_acc: 0.93321\n",
      "\n",
      "final test acc: 0.933207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AdamLR = extend_with_piecewise_linear_lr(Adam, name='AdamLR')\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    optimizer=AdamLR(learning_rate=1e-4, lr_schedule={\n",
    "        1000: 1,\n",
    "        2000: 0.1\n",
    "    }),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "czTbnOCKEJjQ"
   },
   "source": [
    "##### 3.1.2 EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2Z8-iuzD54b"
   },
   "outputs": [],
   "source": [
    "\n",
    "AdamEMA = extend_with_exponential_moving_average(Adam, name='AdamEMA')\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    optimizer=AdamEMA(learning_rate=1e-4),\n",
    "    metrics=['accuracy'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "z1QBNGnSE9Hj",
    "outputId": "c21c2408-bda9-4f6d-c8f3-2af98c8b49ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "264/264 [==============================] - 31s 116ms/step - loss: 0.7227 - accuracy: 0.5087\n",
      "val_acc: 0.49124, best_val_acc: 0.49124, test_acc: 0.49834\n",
      "\n",
      "Epoch 2/5\n",
      "264/264 [==============================] - 28s 108ms/step - loss: 0.7231 - accuracy: 0.5087\n",
      "val_acc: 0.49124, best_val_acc: 0.49124, test_acc: 0.49834\n",
      "\n",
      "Epoch 3/5\n",
      "264/264 [==============================] - 28s 107ms/step - loss: 0.7228 - accuracy: 0.5087\n",
      "val_acc: 0.49124, best_val_acc: 0.49124, test_acc: 0.49834\n",
      "\n",
      "Epoch 4/5\n",
      "264/264 [==============================] - 28s 108ms/step - loss: 0.7230 - accuracy: 0.5087\n",
      "val_acc: 0.49124, best_val_acc: 0.49124, test_acc: 0.49834\n",
      "\n",
      "Epoch 5/5\n",
      "264/264 [==============================] - 28s 108ms/step - loss: 0.7231 - accuracy: 0.5087\n",
      "val_acc: 0.49124, best_val_acc: 0.49124, test_acc: 0.49834\n",
      "\n",
      "final test acc: 0.498342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eK4Q2wrQEPM9"
   },
   "source": [
    "#####3.1.3 梯度累计 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42FNu4S3FnQT"
   },
   "outputs": [],
   "source": [
    "\n",
    "AdamGACC = extend_with_gradient_accumulation(Adam, name='AdamGACC')\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    optimizer=AdamGACC(learning_rate=1e-4),\n",
    "    metrics=['accuracy'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "VylZvHjyEAhn",
    "outputId": "7ed45b6f-87f9-42fa-aaee-089d4f6dd838"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "264/264 [==============================] - 89s 337ms/step - loss: 0.4022 - accuracy: 0.8081\n",
      "val_acc: 0.90242, best_val_acc: 0.90242, test_acc: 0.90289\n",
      "\n",
      "Epoch 2/5\n",
      "264/264 [==============================] - 85s 323ms/step - loss: 0.1898 - accuracy: 0.9279\n",
      "val_acc: 0.92942, best_val_acc: 0.92942, test_acc: 0.92184\n",
      "\n",
      "Epoch 3/5\n",
      "264/264 [==============================] - 85s 323ms/step - loss: 0.0912 - accuracy: 0.9666\n",
      "val_acc: 0.92326, best_val_acc: 0.92942, test_acc: 0.92468\n",
      "\n",
      "Epoch 4/5\n",
      "264/264 [==============================] - 85s 323ms/step - loss: 0.0388 - accuracy: 0.9867\n",
      "val_acc: 0.94458, best_val_acc: 0.94458, test_acc: 0.93273\n",
      "\n",
      "Epoch 5/5\n",
      "264/264 [==============================] - 85s 322ms/step - loss: 0.0263 - accuracy: 0.9910\n",
      "val_acc: 0.93084, best_val_acc: 0.94458, test_acc: 0.92136\n",
      "\n",
      "final test acc: 0.921364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator()\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "\n",
    "#model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZwaLqP2IQPH"
   },
   "source": [
    "##### 3.3.4 层自适应\n",
    "extend_with_layer_adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "BSv7RJ9HIU9-",
    "outputId": "b389df14-f2ff-4ea3-e66a-6578282c1744"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "264/264 [==============================] - 89s 338ms/step - loss: 0.3888 - accuracy: 0.8168\n",
      "val_acc: 0.91805, best_val_acc: 0.91805, test_acc: 0.91047\n",
      "\n",
      "Epoch 2/5\n",
      "264/264 [==============================] - 86s 325ms/step - loss: 0.1841 - accuracy: 0.9318\n",
      "val_acc: 0.93605, best_val_acc: 0.93605, test_acc: 0.93368\n",
      "\n",
      "Epoch 3/5\n",
      "264/264 [==============================] - 86s 325ms/step - loss: 0.1074 - accuracy: 0.9622\n",
      "val_acc: 0.94458, best_val_acc: 0.94458, test_acc: 0.93463\n",
      "\n",
      "Epoch 4/5\n",
      "264/264 [==============================] - 86s 325ms/step - loss: 0.0598 - accuracy: 0.9808\n",
      "val_acc: 0.94126, best_val_acc: 0.94458, test_acc: 0.93510\n",
      "\n",
      "Epoch 5/5\n",
      "264/264 [==============================] - 86s 324ms/step - loss: 0.0335 - accuracy: 0.9892\n",
      "val_acc: 0.93794, best_val_acc: 0.94458, test_acc: 0.93652\n",
      "\n",
      "final test acc: 0.934628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AdamLA = extend_with_layer_adaptation(Adam, name='AdamLA')\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    optimizer=AdamLA(learning_rate=1e-4),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "evaluator = Evaluator()\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qLSjX8lRH9UP"
   },
   "source": [
    "##### 3.3.5 权重衰减  \n",
    "extend_with_weight_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "Lh6KYOrFIA64",
    "outputId": "a4d5c192-1a9c-4732-c3fd-bee73980a008"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "264/264 [==============================] - 86s 326ms/step - loss: 0.1451 - accuracy: 0.9462\n",
      "val_acc: 0.94315, best_val_acc: 0.94315, test_acc: 0.93558\n",
      "\n",
      "Epoch 2/5\n",
      "264/264 [==============================] - 83s 315ms/step - loss: 0.0742 - accuracy: 0.9739\n",
      "val_acc: 0.93842, best_val_acc: 0.94315, test_acc: 0.93321\n",
      "\n",
      "Epoch 3/5\n",
      "264/264 [==============================] - 83s 316ms/step - loss: 0.0477 - accuracy: 0.9834\n",
      "val_acc: 0.93368, best_val_acc: 0.94315, test_acc: 0.94031\n",
      "\n",
      "Epoch 4/5\n",
      "264/264 [==============================] - 83s 316ms/step - loss: 0.0336 - accuracy: 0.9884\n",
      "val_acc: 0.94268, best_val_acc: 0.94315, test_acc: 0.93937\n",
      "\n",
      "Epoch 5/5\n",
      "264/264 [==============================] - 83s 315ms/step - loss: 0.0265 - accuracy: 0.9898\n",
      "val_acc: 0.93605, best_val_acc: 0.94315, test_acc: 0.93842\n",
      "\n",
      "final test acc: 0.935576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AdamWdecay = extend_with_weight_decay(Adam, name='AdamWdecay')\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    optimizer=AdamWdecay(learning_rate=1e-4, ),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "evaluator = Evaluator()\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnWJ39Y3K4RG"
   },
   "source": [
    "##### 3.3.6 lookahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "colab_type": "code",
    "id": "VP9CxdoCIGTW",
    "outputId": "3125fe51-b5ee-49b9-9a28-739af3e0f0a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3c8b76706bae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m                 initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m:  Error while reading resource variable _AnonymousVar636 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar636/N10tensorflow3VarE does not exist.\n\t [[node ReadVariableOp_394 (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_26546]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "\n",
    "AdamLahead = extend_with_lookahead(Adam, name='AdamLahead')\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=AdamLahead(learning_rate=1e-4),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "evaluator = Evaluator()\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "miQi0fAlWYU7"
   },
   "source": [
    "#### 3.2 SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "baSlojjnWhNK"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "syWctRG1WUzp",
    "outputId": "29091146-58ff-4540-c6fb-e0900437e3ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "264/264 [==============================] - 255s 966ms/step - loss: 0.1008 - accuracy: 0.9636\n",
      "val_acc: 0.93368, best_val_acc: 0.93368, test_acc: 0.93273\n",
      "\n",
      "Epoch 2/5\n",
      "264/264 [==============================] - 254s 961ms/step - loss: 0.0748 - accuracy: 0.9749\n",
      "val_acc: 0.93889, best_val_acc: 0.93889, test_acc: 0.94315\n",
      "\n",
      "Epoch 3/5\n",
      "264/264 [==============================] - 253s 960ms/step - loss: 0.0569 - accuracy: 0.9799\n",
      "val_acc: 0.93842, best_val_acc: 0.93889, test_acc: 0.93558\n",
      "\n",
      "Epoch 4/5\n",
      "264/264 [==============================] - 253s 959ms/step - loss: 0.0445 - accuracy: 0.9837\n",
      "val_acc: 0.93984, best_val_acc: 0.93984, test_acc: 0.94552\n",
      "\n",
      "Epoch 5/5\n",
      "264/264 [==============================] - 253s 959ms/step - loss: 0.0324 - accuracy: 0.9889\n",
      "val_acc: 0.93842, best_val_acc: 0.93984, test_acc: 0.94079\n",
      "\n",
      "final test acc: 0.945523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=SGD(learning_rate=1e-3, decay=1e-6, momentum=0.9),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "evaluator = Evaluator()\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2A-0_plWHyu"
   },
   "source": [
    "###### SGD+lookahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "Ut-7MKSbPNW4",
    "outputId": "e2b25c71-5076-4372-e862-e91fe87e9903"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "264/264 [==============================] - 257s 974ms/step - loss: 0.4199 - accuracy: 0.7964\n",
      "val_acc: 0.90099, best_val_acc: 0.90099, test_acc: 0.89010\n",
      "\n",
      "Epoch 2/5\n",
      "264/264 [==============================] - 255s 967ms/step - loss: 0.2518 - accuracy: 0.9061\n",
      "val_acc: 0.91047, best_val_acc: 0.91047, test_acc: 0.91000\n",
      "\n",
      "Epoch 3/5\n",
      "264/264 [==============================] - 255s 967ms/step - loss: 0.1951 - accuracy: 0.9278\n",
      "val_acc: 0.91900, best_val_acc: 0.91900, test_acc: 0.92184\n",
      "\n",
      "Epoch 4/5\n",
      "264/264 [==============================] - 255s 967ms/step - loss: 0.1591 - accuracy: 0.9420\n",
      "val_acc: 0.92326, best_val_acc: 0.92326, test_acc: 0.91852\n",
      "\n",
      "Epoch 5/5\n",
      "264/264 [==============================] - 256s 968ms/step - loss: 0.1293 - accuracy: 0.9529\n",
      "val_acc: 0.93652, best_val_acc: 0.93652, test_acc: 0.93558\n",
      "\n",
      "final test acc: 0.935576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "SGDLhead = extend_with_weight_decay(SGD, name='SGDLhead')\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    optimizer=SGDLhead(learning_rate=1e-3, decay=1e-6, momentum=0.9),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "evaluator = Evaluator()\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tTWnv_vUOZzl"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3IMMmTWiO9Ld"
   },
   "source": [
    "#### 3.3 AdaFactor\n",
    "这个优化器lr batch_size 需要大一点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "iAMzvvclZIHj",
    "outputId": "c37802e0-a47e-400f-8fc4-bb30c8f43973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'adafactor'...\n",
      "remote: Enumerating objects: 18, done.\u001b[K\n",
      "remote: Counting objects:   5% (1/18)\u001b[K\r",
      "remote: Counting objects:  11% (2/18)\u001b[K\r",
      "remote: Counting objects:  16% (3/18)\u001b[K\r",
      "remote: Counting objects:  22% (4/18)\u001b[K\r",
      "remote: Counting objects:  27% (5/18)\u001b[K\r",
      "remote: Counting objects:  33% (6/18)\u001b[K\r",
      "remote: Counting objects:  38% (7/18)\u001b[K\r",
      "remote: Counting objects:  44% (8/18)\u001b[K\r",
      "remote: Counting objects:  50% (9/18)\u001b[K\r",
      "remote: Counting objects:  55% (10/18)\u001b[K\r",
      "remote: Counting objects:  61% (11/18)\u001b[K\r",
      "remote: Counting objects:  66% (12/18)\u001b[K\r",
      "remote: Counting objects:  72% (13/18)\u001b[K\r",
      "remote: Counting objects:  77% (14/18)\u001b[K\r",
      "remote: Counting objects:  83% (15/18)\u001b[K\r",
      "remote: Counting objects:  88% (16/18)\u001b[K\r",
      "remote: Counting objects:  94% (17/18)\u001b[K\r",
      "remote: Counting objects: 100% (18/18)\u001b[K\r",
      "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
      "remote: Compressing objects:   6% (1/15)\u001b[K\r",
      "remote: Compressing objects:  13% (2/15)\u001b[K\r",
      "remote: Compressing objects:  20% (3/15)\u001b[K\r",
      "remote: Compressing objects:  26% (4/15)\u001b[K\r",
      "remote: Compressing objects:  33% (5/15)\u001b[K\r",
      "remote: Compressing objects:  40% (6/15)\u001b[K\r",
      "remote: Compressing objects:  46% (7/15)\u001b[K\r",
      "remote: Compressing objects:  53% (8/15)\u001b[K\r",
      "remote: Compressing objects:  60% (9/15)\u001b[K\r",
      "remote: Compressing objects:  66% (10/15)\u001b[K\r",
      "remote: Compressing objects:  73% (11/15)\u001b[K\r",
      "remote: Compressing objects:  80% (12/15)\u001b[K\r",
      "remote: Compressing objects:  86% (13/15)\u001b[K\r",
      "remote: Compressing objects:  93% (14/15)\u001b[K\r",
      "remote: Compressing objects: 100% (15/15)\u001b[K\r",
      "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
      "remote: Total 18 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects:   5% (1/18)   \r",
      "Unpacking objects:  11% (2/18)   \r",
      "Unpacking objects:  16% (3/18)   \r",
      "Unpacking objects:  22% (4/18)   \r",
      "Unpacking objects:  27% (5/18)   \r",
      "Unpacking objects:  33% (6/18)   \r",
      "Unpacking objects:  38% (7/18)   \r",
      "Unpacking objects:  44% (8/18)   \r",
      "Unpacking objects:  50% (9/18)   \r",
      "Unpacking objects:  55% (10/18)   \r",
      "Unpacking objects:  61% (11/18)   \r",
      "Unpacking objects:  66% (12/18)   \r",
      "Unpacking objects:  72% (13/18)   \r",
      "Unpacking objects:  77% (14/18)   \r",
      "Unpacking objects:  83% (15/18)   \r",
      "Unpacking objects:  88% (16/18)   \r",
      "Unpacking objects:  94% (17/18)   \r",
      "Unpacking objects: 100% (18/18)   \r",
      "Unpacking objects: 100% (18/18), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/bojone/adafactor.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ABuaR7ZuZNCt"
   },
   "outputs": [],
   "source": [
    "from adafactor.adafactor import AdaFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "colab_type": "code",
    "id": "tndhxEA6O557",
    "outputId": "7869bd62-fabb-40aa-b60c-d7bc5a76d822"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 11/264 [>.............................] - ETA: 2:20 - loss: nan - accuracy: 0.4673"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-7f7d005f6d3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m                 initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=AdaFactor(1e-3),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "\n",
    "model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "colab_type": "code",
    "id": "HoB35AEyVsC3",
    "outputId": "dfa36502-a63d-42b9-fb21-20864427e3b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 79/264 [=======>......................] - ETA: 1:07 - loss: nan - accuracy: 0.4909"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ef8550e8a401>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m                 initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "AdaFLR = extend_with_piecewise_linear_lr(AdaFactor, name='AdaFLR')\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=AdaFLR(learning_rate=1e-2, lr_schedule={\n",
    "        1000: 1,\n",
    "        3000: 0.1\n",
    "    }),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "\n",
    "#model.load_weights('best_model.weights')\n",
    "\n",
    "\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aUFqbhO44pmJ"
   },
   "source": [
    "#### 3.4 Adax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "3i2gz_fB4pEs",
    "outputId": "cb98fb87-f7d4-4123-e0e0-70a8fbff385c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'adax'...\n",
      "remote: Enumerating objects: 12, done.\u001b[K\n",
      "remote: Counting objects:   8% (1/12)\u001b[K\r",
      "remote: Counting objects:  16% (2/12)\u001b[K\r",
      "remote: Counting objects:  25% (3/12)\u001b[K\r",
      "remote: Counting objects:  33% (4/12)\u001b[K\r",
      "remote: Counting objects:  41% (5/12)\u001b[K\r",
      "remote: Counting objects:  50% (6/12)\u001b[K\r",
      "remote: Counting objects:  58% (7/12)\u001b[K\r",
      "remote: Counting objects:  66% (8/12)\u001b[K\r",
      "remote: Counting objects:  75% (9/12)\u001b[K\r",
      "remote: Counting objects:  83% (10/12)\u001b[K\r",
      "remote: Counting objects:  91% (11/12)\u001b[K\r",
      "remote: Counting objects: 100% (12/12)\u001b[K\r",
      "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
      "remote: Compressing objects:  11% (1/9)\u001b[K\r",
      "remote: Compressing objects:  22% (2/9)\u001b[K\r",
      "remote: Compressing objects:  33% (3/9)\u001b[K\r",
      "remote: Compressing objects:  44% (4/9)\u001b[K\r",
      "remote: Compressing objects:  55% (5/9)\u001b[K\r",
      "remote: Compressing objects:  66% (6/9)\u001b[K\r",
      "remote: Compressing objects:  77% (7/9)\u001b[K\r",
      "remote: Compressing objects:  88% (8/9)\u001b[K\r",
      "remote: Compressing objects: 100% (9/9)\u001b[K\r",
      "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
      "remote: Total 12 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects:   8% (1/12)   \r",
      "Unpacking objects:  16% (2/12)   \r",
      "Unpacking objects:  25% (3/12)   \r",
      "Unpacking objects:  33% (4/12)   \r",
      "Unpacking objects:  41% (5/12)   \r",
      "Unpacking objects:  50% (6/12)   \r",
      "Unpacking objects:  58% (7/12)   \r",
      "Unpacking objects:  66% (8/12)   \r",
      "Unpacking objects:  75% (9/12)   \r",
      "Unpacking objects:  83% (10/12)   \r",
      "Unpacking objects:  91% (11/12)   \r",
      "Unpacking objects: 100% (12/12)   \r",
      "Unpacking objects: 100% (12/12), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/bojone/adax.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JCpYFuAb41f2"
   },
   "outputs": [],
   "source": [
    "from adax.adax import AdaX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "id": "KDW2ElOT4C-w",
    "outputId": "4fe7dbb1-b388-496d-db2e-b5afb4c601cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "264/264 [==============================] - 151s 572ms/step - loss: 0.5147 - accuracy: 0.7696\n",
      "val_acc: 0.77546, best_val_acc: 0.77546, test_acc: 0.76883\n",
      "\n",
      "Epoch 2/5\n",
      "264/264 [==============================] - 157s 593ms/step - loss: 0.6946 - accuracy: 0.5071\n",
      "val_acc: 0.50876, best_val_acc: 0.77546, test_acc: 0.50166\n",
      "\n",
      "Epoch 3/5\n",
      "227/264 [========================>.....] - ETA: 21s - loss: 0.6946 - accuracy: 0.5162"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-3),  # 用足够小的学习率\n",
    "    optimizer=AdaX(1e-4),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "\n",
    "#model.load_weights('best_model.weights')\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JY1oI3DRTEM6"
   },
   "source": [
    "##### 3.4.1 线性分段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "iTgwYdDH9d8T",
    "outputId": "5b6d4b44-397b-43a5-d852-d5bac5eba5a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "264/264 [==============================] - 86s 327ms/step - loss: 0.0569 - accuracy: 0.9803\n",
      "val_acc: 0.87210, best_val_acc: 0.87210, test_acc: 0.87636\n",
      "\n",
      "Epoch 2/5\n",
      "264/264 [==============================] - 84s 317ms/step - loss: 0.1605 - accuracy: 0.9404\n",
      "val_acc: 0.90715, best_val_acc: 0.90715, test_acc: 0.90810\n",
      "\n",
      "Epoch 3/5\n",
      "264/264 [==============================] - 84s 317ms/step - loss: 0.2073 - accuracy: 0.9225\n",
      "val_acc: 0.88868, best_val_acc: 0.90715, test_acc: 0.87541\n",
      "\n",
      "Epoch 4/5\n",
      "264/264 [==============================] - 84s 317ms/step - loss: 0.3851 - accuracy: 0.8389\n",
      "val_acc: 0.84462, best_val_acc: 0.90715, test_acc: 0.83562\n",
      "\n",
      "Epoch 5/5\n",
      "264/264 [==============================] - 84s 317ms/step - loss: 0.3218 - accuracy: 0.8721\n",
      "val_acc: 0.85836, best_val_acc: 0.90715, test_acc: 0.85505\n",
      "\n",
      "final test acc: 0.855045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=AdaXLR(learning_rate=1e-3, lr_schedule={\n",
    "        1000: 1,\n",
    "        2000: 0.1\n",
    "    }),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    callbacks=[evaluator]\n",
    ")\n",
    "\n",
    "#model.load_weights('best_model.weights')\n",
    "AdaXLR = extend_with_piecewise_linear_lr(Adam, name='AdaXLR')\n",
    "\n",
    "print(u'final test acc: %05f\\n' % (evaluate(test_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KODykQovORRn"
   },
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-vPSOjtTOVIX"
   },
   "source": [
    "# part 4 错误分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5U6-p8YkOWF8"
   },
   "outputs": [],
   "source": [
    "# 打印错误数\n",
    "num = 6\n",
    "tag = 0\n",
    "for x_true, y_true in test_generator:\n",
    "    tag +=1\n",
    "    if tag>num:\n",
    "      break\n",
    "    #print(x_true[0].shape)\n",
    "    y_pred = model.predict(x_true).argmax(axis=1)\n",
    "    y_true = y_true[:, 0]\n",
    "    #print(y_true)\n",
    "    #print(y_pred)\n",
    "    #error_pred = x_true[0][y_true!=y_pred]\n",
    "    error_ids = np.array(list(range(len(y_true))))[y_true!=y_pred]\n",
    "\n",
    "    print(error_ids)\n",
    "    for ids in error_ids:\n",
    "      print('text :{}\\npredict:{}, ture:{}\\n'.format(tokenizer.decode(x_true[0][ids]),y_pred[ids],y_true[ids]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "phkg2GGX0Hji"
   },
   "source": [
    "# 重启"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "rVwmoCTt0HDP",
    "outputId": "afa8beaf-8139-42ed-8868-655df09cc414"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'apt autoremove' to remove it.\n",
      "The following NEW packages will be installed:\n",
      "  psmisc\n",
      "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
      "Need to get 52.5 kB of archives.\n",
      "After this operation, 266 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 psmisc amd64 23.1-1ubuntu0.1 [52.5 kB]\n",
      "Fetched 52.5 kB in 0s (1,074 kB/s)\n",
      "Selecting previously unselected package psmisc.\n",
      "(Reading database ... 144465 files and directories currently installed.)\n",
      "Preparing to unpack .../psmisc_23.1-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking psmisc (23.1-1ubuntu0.1) ...\n",
      "Setting up psmisc (23.1-1ubuntu0.1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "/dev/nvidia0:          122m\n",
      "/dev/nvidiactl:        122m\n",
      "/dev/nvidia-uvm:       122m\n"
     ]
    }
   ],
   "source": [
    "# 重启\n",
    "!apt install psmisc\n",
    "!sudo fuser /dev/nvidia*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOYWkB-c0MrU"
   },
   "outputs": [],
   "source": [
    "! kill -9 122"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "compare_optimizer_bert_base.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
